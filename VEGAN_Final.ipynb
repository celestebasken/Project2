{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a75984ca-08f3-4d38-9166-79d441c22d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eep153_tools in /srv/conda/lib/python3.11/site-packages (0.12.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python_gnupg in /srv/conda/lib/python3.11/site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gspread_pandas in /srv/conda/lib/python3.11/site-packages (3.3.0)\n",
      "Requirement already satisfied: gspread<6,>=5.0.0 in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (5.12.4)\n",
      "Requirement already satisfied: pandas>=0.20.0 in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (2.2.3)\n",
      "Requirement already satisfied: decorator in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (5.1.1)\n",
      "Requirement already satisfied: google-auth in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /srv/conda/lib/python3.11/site-packages (from google-auth-oauthlib->gspread_pandas) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /srv/conda/lib/python3.11/site-packages (from pandas>=0.20.0->gspread_pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/lib/python3.11/site-packages (from pandas>=0.20.0->gspread_pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/lib/python3.11/site-packages (from pandas>=0.20.0->gspread_pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/lib/python3.11/site-packages (from pandas>=0.20.0->gspread_pandas) (2025.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /srv/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth->gspread_pandas) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->gspread_pandas) (1.17.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /srv/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /srv/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install eep153_tools\n",
    "%pip install python_gnupg\n",
    "%pip install -U gspread_pandas\n",
    "#load in file from class\n",
    "def format_id(id,zeropadding=0):\n",
    "    \"\"\"Nice string format for any id, string or numeric.\n",
    "\n",
    "    Optional zeropadding parameter takes an integer\n",
    "    formats as {id:0z} where\n",
    "    \"\"\"\n",
    "    if pd.isnull(id) or id in ['','.']: return None\n",
    "\n",
    "    try:  # If numeric, return as string int\n",
    "        return ('%d' % id).zfill(zeropadding)\n",
    "    except TypeError:  # Not numeric\n",
    "        return id.split('.')[0].strip().zfill(zeropadding)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "data_url = \"https://docs.google.com/spreadsheets/d/1GTo423_gUJe1Von9jypWAbC0zSQ7WGegAWPuRi7eJAI/edit?gid=1410082681#gid=1410082681\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f10138f-ba5d-4e3c-ac9b-3220baf9f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_foodcode</th>\n",
       "      <th>recipe</th>\n",
       "      <th>ingred_code</th>\n",
       "      <th>ingred_desc</th>\n",
       "      <th>ingred_wt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11340000</td>\n",
       "      <td>Imitation milk, non-soy, sweetened</td>\n",
       "      <td>43543</td>\n",
       "      <td>Milk, imitation, non-soy</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11460150</td>\n",
       "      <td>Yogurt, frozen, NS as to flavor, lowfat milk</td>\n",
       "      <td>1298</td>\n",
       "      <td>Yogurt, frozen, flavors other than chocolate, ...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>1117</td>\n",
       "      <td>Yogurt, plain, low fat, 12 grams protein per 8...</td>\n",
       "      <td>81.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>19166</td>\n",
       "      <td>Cocoa, dry powder, unsweetened, processed with...</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>19335</td>\n",
       "      <td>Sugars, granulated</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_foodcode                                        recipe ingred_code  \\\n",
       "0        11340000            Imitation milk, non-soy, sweetened       43543   \n",
       "1        11460150  Yogurt, frozen, NS as to flavor, lowfat milk        1298   \n",
       "2        11460160        Yogurt, frozen, chocolate, lowfat milk        1117   \n",
       "3        11460160        Yogurt, frozen, chocolate, lowfat milk       19166   \n",
       "4        11460160        Yogurt, frozen, chocolate, lowfat milk       19335   \n",
       "\n",
       "                                         ingred_desc  ingred_wt  \n",
       "0                           Milk, imitation, non-soy      100.0  \n",
       "1  Yogurt, frozen, flavors other than chocolate, ...      100.0  \n",
       "2  Yogurt, plain, low fat, 12 grams protein per 8...       81.8  \n",
       "3  Cocoa, dry powder, unsweetened, processed with...        5.2  \n",
       "4                                 Sugars, granulated       13.0  "
      ]
     },

     "execution_count": 46,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from eep153_tools.sheets import read_sheets\n",
    "\n",
    "#create recipes df\n",
    "recipes = read_sheets(data_url, sheet=\"recipes\")\n",
    "recipes = (recipes\n",
    "           .assign(parent_foodcode = lambda df: df[\"parent_foodcode\"].apply(format_id),\n",
    "                   ingred_code = lambda df: df[\"ingred_code\"].apply(format_id))\n",
    "           .rename(columns={\"parent_desc\": \"recipe\"}))\n",
    "recipes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4f37ab6-a060-4139-b69d-ad6c52cf40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of non-vegan keywords AND non-natural foods keywords (including frozen, processed, etc).\n",
    "NON_VEGAN_KEYWORDS = [\n",
    "    \"beef\", \"pork\", \"chicken\", \"turkey\", \"fish\", \"seafood\", \"shellfish\", \"shrimp\", \"crab\",\"crabs\",\n",
    "    \"lamb\", \"goat\", \"duck\", \"goose\", \"tuna\", \"salmon\", \"cod\", \"bacon\", \"ham\",\n",
    "    \"shellfish\", \"lobster\", \"mussels\", \"oysters\", \"scallops\", \"octopus\", \"eel\",\n",
    "    \"organ meat\", \"milk\",\"Eggnog\" \"cheese\", \"butter\", \"cream\",\"ice cream\", \"yogurt\", \"whey\",\n",
    "    \"casein\", \"lactose\", \"ghee\", \"buttermilk\", \"egg\", \"eggs\", \"mayo\", \"mayonnaise\", \"albumen\",\n",
    "    \"albumin\", \"lysozyme\", \"ovomucoid\", \"ovomucin\", \"ovovitellin\", \"honey\",\n",
    "    \"bee pollen\", \"royal jelly\", \"propolis\", \"shellac\", \"confectioner’s glaze\",\n",
    "    \"carmine\", \"cochineal\", \"lard\", \"tallow\", \"suet\", \"gelatin\", \"collagen\",\n",
    "    \"isinglass\", \"bone broth\", \"bone stock\", \"fish sauce\", \"oyster sauce\",\n",
    "    \"shrimp paste\", \"worcestershire sauce\", \"anchovies\", \"rennet\", \"pepsin\",\n",
    "    \"bone char\", \"vitamin d3\", \"lanolin\", \"omega-3 fish oil\", \"caseinate\",\n",
    "    \"lecithin (egg)\", \"cysteine\", \"l-cysteine\", \"glycerin (animal)\",\n",
    "    \"glycerol (animal)\", \"stearic acid (animal)\", \"tallowate\", \"sodium tallowate\",\n",
    "    \"capric acid\", \"caprylic acid\", \"cheese\", \"pudding\", \"processed\", \"veal\",'sirloin', \"steak\", \"animal\",\n",
    "    \"Custard\", \"Mousse\", \"chocolate\", \"Meatballs\", \"meat\", \"Gravy\", \"poultry\",\"baby\", \"frozen\", 'dairy', 'lump',\"peas\",\"school\"\n",
    "]\n",
    "\n",
    "#this partal match: \"milkshake\" or \"eggroll\" will get flagged (since \"milk\" or \"egg\" is in the keyword list).\n",
    "NON_VEGAN_PATTERN = re.compile(\n",
    "    '|'.join(map(re.escape, NON_VEGAN_KEYWORDS)),\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def filter_vegan_ingredients(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 1) Convert to string, lowercase, remove punctuation\n",
    "    df[\"recipe\"] = df[\"recipe\"].astype(str).str.lower().fillna(\"\")\n",
    "    df[\"recipe\"] = df[\"recipe\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "    df[\"ingred_desc\"] = df[\"ingred_desc\"].astype(str).str.lower().fillna(\"\")\n",
    "    df[\"ingred_desc\"] = df[\"ingred_desc\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "    # 2) Create a mask for rows that do NOT contain non-vegan keywords\n",
    "    mask = ~(df[\"recipe\"].str.contains(NON_VEGAN_PATTERN, na=False, regex=True) |\n",
    "             df[\"ingred_desc\"].str.contains(NON_VEGAN_PATTERN, na=False, regex=True))\n",
    "\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a72e0efe-81c5-4844-b116-3ff371adc7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11137, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_recipes = filter_vegan_ingredients(recipes)\n",
    "vegan_recipes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75ff8ffe-65da-40bf-90e6-a083f7c9732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingred_code</th>\n",
       "      <th>Ingredient description</th>\n",
       "      <th>Capric acid</th>\n",
       "      <th>Lauric acid</th>\n",
       "      <th>Myristic acid</th>\n",
       "      <th>Palmitic acid</th>\n",
       "      <th>Palmitoleic acid</th>\n",
       "      <th>Stearic acid</th>\n",
       "      <th>Oleic acid</th>\n",
       "      <th>Linoleic Acid</th>\n",
       "      <th>...</th>\n",
       "      <th>Vitamin B12</th>\n",
       "      <th>Vitamin B-12, added</th>\n",
       "      <th>Vitamin B6</th>\n",
       "      <th>Vitamin C</th>\n",
       "      <th>Vitamin D</th>\n",
       "      <th>Vitamin E</th>\n",
       "      <th>Vitamin E, added</th>\n",
       "      <th>Vitamin K</th>\n",
       "      <th>Water</th>\n",
       "      <th>Zinc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>2.529</td>\n",
       "      <td>2.587</td>\n",
       "      <td>7.436</td>\n",
       "      <td>21.697</td>\n",
       "      <td>0.961</td>\n",
       "      <td>9.999</td>\n",
       "      <td>19.961</td>\n",
       "      <td>2.728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.87</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>2.039</td>\n",
       "      <td>2.354</td>\n",
       "      <td>7.515</td>\n",
       "      <td>20.531</td>\n",
       "      <td>1.417</td>\n",
       "      <td>7.649</td>\n",
       "      <td>17.370</td>\n",
       "      <td>2.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.793</td>\n",
       "      <td>10.005</td>\n",
       "      <td>26.166</td>\n",
       "      <td>2.228</td>\n",
       "      <td>12.056</td>\n",
       "      <td>25.026</td>\n",
       "      <td>2.247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.491</td>\n",
       "      <td>3.301</td>\n",
       "      <td>9.153</td>\n",
       "      <td>0.816</td>\n",
       "      <td>3.235</td>\n",
       "      <td>6.622</td>\n",
       "      <td>0.536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>42.41</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.482</td>\n",
       "      <td>3.227</td>\n",
       "      <td>8.655</td>\n",
       "      <td>0.817</td>\n",
       "      <td>3.455</td>\n",
       "      <td>7.401</td>\n",
       "      <td>0.491</td>\n",
       "      <td>...</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>41.11</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ingred_code      Ingredient description  Capric acid  Lauric acid  \\\n",
       "0        1001              Butter, salted        2.529        2.587   \n",
       "1        1002  Butter, whipped, with salt        2.039        2.354   \n",
       "2        1003       Butter oil, anhydrous        2.495        2.793   \n",
       "3        1004                Cheese, blue        0.601        0.491   \n",
       "4        1005               Cheese, brick        0.585        0.482   \n",
       "\n",
       "   Myristic acid  Palmitic acid  Palmitoleic acid  Stearic acid  Oleic acid  \\\n",
       "0          7.436         21.697             0.961         9.999      19.961   \n",
       "1          7.515         20.531             1.417         7.649      17.370   \n",
       "2         10.005         26.166             2.228        12.056      25.026   \n",
       "3          3.301          9.153             0.816         3.235       6.622   \n",
       "4          3.227          8.655             0.817         3.455       7.401   \n",
       "\n",
       "   Linoleic Acid  ...  Vitamin B12  Vitamin B-12, added  Vitamin B6  \\\n",
       "0          2.728  ...         0.17                  0.0       0.003   \n",
       "1          2.713  ...         0.07                  0.0       0.008   \n",
       "2          2.247  ...         0.01                  0.0       0.001   \n",
       "3          0.536  ...         1.22                  0.0       0.166   \n",
       "4          0.491  ...         1.26                  0.0       0.065   \n",
       "\n",
       "   Vitamin C  Vitamin D  Vitamin E  Vitamin E, added  Vitamin K  Water  Zinc  \n",
       "0        0.0        0.0       2.32               0.0        7.0  15.87  0.09  \n",
       "1        0.0        0.0       1.37               0.0        4.6  16.72  0.05  \n",
       "2        0.0        0.0       2.80               0.0        8.6   0.24  0.01  \n",
       "3        0.0        0.5       0.25               0.0        2.4  42.41  2.66  \n",
       "4        0.0        0.5       0.26               0.0        2.5  41.11  2.60  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe_id\n",
      "11115400    kefir ns as to fat content\n",
      "11440060                  tzatziki dip\n",
      "11551050             licuado or batido\n",
      "11553100            fruit smoothie nfs\n",
      "11710000            infant formula nfs\n",
      "Name: recipe, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160/3073712158.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vegan_recipes['ingred_wt'] = vegan_recipes['ingred_wt']/vegan_recipes.groupby(['parent_foodcode'])['ingred_wt'].transform(\"sum\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3893, 66)"
      ]
     },
     "execution_count": 49,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start copying code from mini lecture VEGAN\n",
    "\n",
    "#create nutrition df\n",
    "nutrition = (read_sheets(data_url, sheet=\"nutrients\")\n",
    "             .assign(ingred_code = lambda df: df[\"ingred_code\"].apply(format_id)))\n",
    "\n",
    "display(nutrition.head())\n",
    "nutrition.columns\n",
    "nutrition.shape\n",
    "\n",
    "\n",
    "\n",
    "# normalize weights to percentage terms. \n",
    "vegan_recipes['ingred_wt'] = vegan_recipes['ingred_wt']/vegan_recipes.groupby(['parent_foodcode'])['ingred_wt'].transform(\"sum\")\n",
    "\n",
    "# we're going to extend the recipes data frame to include the nutrient profiles of its ingredients (in 100g)\n",
    "df_vegan = vegan_recipes.merge(nutrition, how=\"left\", on=\"ingred_code\")\n",
    "\n",
    "# multiply all nutrients per 100g of an ingredient by the weight of that ingredient in a recipe.\n",
    "numeric_cols = list(df_vegan.select_dtypes(include=[\"number\"]).columns)\n",
    "numeric_cols.remove(\"ingred_wt\")\n",
    "df_vegan[numeric_cols] = df_vegan[numeric_cols].mul(df_vegan[\"ingred_wt\"], axis=0)\n",
    "\n",
    "# sum nutrients of food codes (over the multiple ingredients)\n",
    "# python tip: one can merge dictionaries dict1 dict2 using **, that is: dict_merge = {**dict1, **dict2}. The ** effectively \"unpacks\" the key value pairs in each dictionary\n",
    "df_vegan = df_vegan.groupby('parent_foodcode').agg({**{col: \"sum\" for col in numeric_cols},\n",
    "                                        \"recipe\": \"first\"})\n",
    "\n",
    "df_vegan.index.name = \"recipe_id\"\n",
    "\n",
    "food_names = df_vegan[\"recipe\"]\n",
    "print(food_names.head())\n",
    "df_vegan.head()\n",
    "df_vegan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,

   "id": "352dfbc1-6bec-4f3e-8e5b-36b7b825f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2011/2012', '2013/2014', '2015/2016', '2017/2018'], dtype='object', name='year')\n",
      "We have prices for 4435 unique recipes (FNDDS food codes)\n"
     ]
    }
   ],
   "source": [
    "prices = read_sheets(data_url, sheet=\"prices\")[[\"food_code\", \"year\", \"price\"]]\n",
    "\n",
    "prices[\"food_code\"] = prices[\"food_code\"].apply(format_id)\n",
    "\n",
    "prices = prices.set_index([\"year\", \"food_code\"])\n",
    "print(prices.index.levels[0])\n",
    "\n",
    "# we'll focus on the latest price data\n",
    "prices = prices.xs(\"2017/2018\", level=\"year\")\n",
    "\n",
    "# drop rows of prices where the price is \"NA\"\n",
    "prices = prices.dropna(subset=\"price\")\n",
    "\n",
    "print(f\"We have prices for {prices.shape[0]} unique recipes (FNDDS food codes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc91010d-3430-4537-93f8-3f02896d0a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Nutrient Type', 'Unit', 'Constraint Type', 'Female_19_30',\n",
       "        'Female_endurance_athlete', 'Male_19_30', 'Male_endurance_athlete'],\n",
       "       dtype='object'),\n",
       "               Nutrient Type  Unit Constraint Type  Female_19_30  \\\n",
       " Nutrient                                                          \n",
       " Energy                Macro  kcal             RDA        2000.0   \n",
       " Protein               Macro     g             RDA          46.0   \n",
       " Carbohydrate          Macro     g             RDA         130.0   \n",
       " Dietary Fiber         Macro     g             RDA          28.0   \n",
       " Linoleic Acid         Macro     g              AI          12.0   \n",
       " \n",
       "                Female_endurance_athlete  Male_19_30  Male_endurance_athlete  \n",
       " Nutrient                                                                     \n",
       " Energy                           2800.0      2400.0                  3500.0  \n",
       " Protein                            80.0        56.0                   112.0  \n",
       " Carbohydrate                      488.0       130.0                   560.0  \n",
       " Dietary Fiber                      28.0        33.6                    38.0  \n",
       " Linoleic Acid                      12.0        17.0                    17.0  ,\n",
       "               Nutrient Type  Unit Constraint Type  Female_19_30  \\\n",
       " Nutrient                                                          \n",
       " Energy                Macro  kcal             RDA        2000.0   \n",
       " Protein               Macro     g             RDA          46.0   \n",
       " Carbohydrate          Macro     g             RDA         130.0   \n",
       " Dietary Fiber         Macro     g             RDA          28.0   \n",
       " Linoleic Acid         Macro     g              AI          12.0   \n",
       " \n",
       "                Female_endurance_athlete  Male_19_30  Male_endurance_athlete  \n",
       " Nutrient                                                                     \n",
       " Energy                           2800.0      2400.0                  3500.0  \n",
       " Protein                            80.0        56.0                   112.0  \n",
       " Carbohydrate                      488.0       130.0                   560.0  \n",
       " Dietary Fiber                      28.0        33.6                    38.0  \n",
       " Linoleic Acid                      12.0        17.0                    17.0  )"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add diet requirements\n",
    "\n",
    "rda = read_sheets(data_url, sheet=\"rda\")\n",
    "\n",
    "rda = rda.set_index(\"Nutrient\")\n",
    "rda_min = rda[rda[\"Constraint Type\"].isin([\"RDA\", \"AI\"])].copy()\n",
    "\n",
    "\n",
    "rda.columns, rda.head(), rda_min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,

   "id": "fdd09b5e-c13f-4749-9dfd-09c22a2ff588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       price\n",
      "kefir ns as to fat content                          0.345625\n",
      "tzatziki dip                                        1.217789\n",
      "licuado or batido                                   0.189099\n",
      "fruit smoothie nfs                                  0.462558\n",
      "infant formula readytofeed similac expert care ...  1.074909\n",
      "                 11115400  11440060  11551050  11553100 11710051 11710055  \\\n",
      "Capric acid        0.0195  0.005673   0.00048  0.000813    0.689    0.689   \n",
      "Lauric acid         0.026  0.000273  0.000959  0.001626    0.023    0.023   \n",
      "Myristic acid      0.0945  0.000545  0.000959  0.001626    0.007    0.007   \n",
      "Palmitic acid      0.2805    5.7604  0.053557  0.083665    0.137    0.137   \n",
      "Palmitoleic acid   0.0185  0.638909  0.005183  0.008129    0.003    0.003   \n",
      "\n",
      "                  11710357  11710358 11710377 11710378  ... 95312410 95312560  \\\n",
      "Capric acid       0.078597  0.078597      0.0      0.0  ...      0.0      0.0   \n",
      "Lauric acid       0.486647  0.486647      0.0      0.0  ...      0.0      0.0   \n",
      "Myristic acid     0.183183  0.183183      0.0      0.0  ...      0.0      0.0   \n",
      "Palmitic acid     0.258139  0.258139      0.0      0.0  ...      0.0      0.0   \n",
      "Palmitoleic acid  0.002386  0.002386      0.0      0.0  ...      0.0      0.0   \n",
      "\n",
      "                 95312600 95312700 95313200 95320200 95320500 95322200  \\\n",
      "Capric acid           0.0      0.0      0.0      0.0    0.001      0.0   \n",
      "Lauric acid           0.0      0.0      0.0      0.0    0.004      0.0   \n",
      "Myristic acid         0.0      0.0      0.0      0.0    0.001      0.0   \n",
      "Palmitic acid         0.0      0.0      0.0      0.0    0.001      0.0   \n",
      "Palmitoleic acid      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "                 95322500 95330100  \n",
      "Capric acid           0.0      0.0  \n",
      "Lauric acid           0.0      0.0  \n",
      "Myristic acid         0.0      0.0  \n",
      "Palmitic acid         0.0      0.0  \n",
      "Palmitoleic acid      0.0      0.0  \n",
      "\n",
      "[5 rows x 1834 columns]\n"
     ]
    }
   ],
   "source": [
    "common_recipes = df_vegan.index.intersection(prices.index)\n",
    "\n",
    "# python tip: given a list of indices, \"loc\" both subsets and sorts. \n",
    "df_vegan = df_vegan.loc[common_recipes]\n",
    "prices = prices.loc[common_recipes]\n",
    "\n",
    "# lets remap the price dataframe index to be the actual food names.\n",
    "prices.index = prices.index.map(food_names)\n",
    "\n",
    "A_all = df_vegan.T\n",
    "\n",
    "print(prices.head())\n",
    "print(A_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8aa5cc1b-2ade-49a6-8861-53bbad6acb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmin.shape=(26,)\n",
      "Amin.shape=(26, 1834)\n",
      "bmax.shape=(1,)\n",
      "Amax.shape=(1, 1834)\n",
      "b.shape=(27,)\n",
      "A.shape=(27, 1834)\n",
      "prices.shape=(1834, 1)\n"
     ]
    }
   ],
   "source": [
    "# pick a demographic (column from rda dataframe)\n",
    "'''\n",
    "select from \n",
    "['Female_19_30', 'Female_endurance_athlete', 'Male_19_30', 'Male_endurance_athlete']\n",
    "'''\n",
    "group = \"Female_endurance_athlete\"\n",
    "\n",
    "# create lower bounds and upper bounds.\n",
    "bmin = rda.loc[rda['Constraint Type'].isin(['RDA', 'AI']), group]\n",
    "bmax = rda.loc[rda['Constraint Type'].isin(['UL']), group]\n",
    "\n",
    "# reindex ensures we only keep nutrients in bmin/bmax\n",
    "Amin = A_all.reindex(bmin.index).dropna(how='all')\n",
    "Amax = A_all.reindex(bmax.index).dropna(how='all')\n",
    "\n",
    "b = pd.concat([bmin, -bmax])\n",
    "A = pd.concat([Amin, -Amax])\n",
    "\n",
    "#python tip: by typing \"=\" after the variable name inside the curly braces, it formats the output so we don't have to write f\"variable = {variable}\"\n",
    "print(f\"{bmin.shape=}\")\n",
    "print(f\"{Amin.shape=}\")\n",
    "print(f\"{bmax.shape=}\")\n",
    "print(f\"{Amax.shape=}\")\n",
    "print(f\"{b.shape=}\")\n",
    "print(f\"{A.shape=}\")\n",
    "print(f\"{prices.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816cbc46-fdab-4cd3-8790-eb18e0995ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,

   "id": "46e58d04-887d-485a-8499-ed367f169c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  scipy.optimize import linprog as lp\n",
    "import numpy as np\n",
    "p = prices\n",
    "tol = 1e-6 # Numbers in solution smaller than this (in absolute value) treated as zeros\n",
    "result = lp(p, -A, -b, method='highs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d688f20-3633-4c87-bb42-df3292ece5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of diet for a vegan Female_endurance_athlete is $3.97 per day.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cost of diet for a vegan {group} is ${result.fun:.2f} per day.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "283b0494-ae26-4603-b191-5217f5c77df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of diet for a vegan Female_endurance_athlete is $3.97 per day. \n",
      "\n",
      "As a vegan Female_endurance_athlete you'll be eating (in 100s of grams or milliliters): \n",
      "\n",
      "vermicelli made from soybeans                    3.18\n",
      "peanuts unroasted                                1.04\n",
      "flax seeds                                       0.02\n",
      "cereal toasted oat                               3.40\n",
      "beans and rice with tomatoes                     2.40\n",
      "ripe plantain raw                                1.81\n",
      "cilantro raw                                     0.20\n",
      "nutritional powder mix high protein herbalife    0.07\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# lets mess with the index on price df so they are recipe names not ids.\n",
    "\n",
    "# get the result x in a series with food names\n",
    "diet = pd.Series(result.x,index=prices.index)\n",
    "\n",
    "\n",
    "print(f\"Cost of diet for a vegan {group} is ${result.fun:.2f} per day. \\n\")\n",
    "\n",
    "print(f\"As a vegan {group} you'll be eating (in 100s of grams or milliliters): \\n\")\n",
    "\n",
    "print(round(diet[diet >= tol], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2050940d-120b-4f22-b903-95a91f40fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for deliverable [A] Dietary Reference Intakes\n",
    "\n",
    "#NEED TO ADD MORE categories into the Google sheet to make better, females, males of different ages, etc.\n",
    "def get_population_dri(population, rda_df) -> pd.Series:\n",
    "    \n",
    "    # 1. Filter rows to only those where Constraint Type is RDA or AI\n",
    "    rda_filtered = rda_df[rda_df[\"Constraint Type\"].isin([\"RDA\", \"AI\"])].copy()\n",
    "\n",
    "    # 3. Extract the column for the chosen population as a Series\n",
    "    dri_series = rda_filtered[population]\n",
    "\n",
    "    # 4. Drop any rows that are NaN (just in case)\n",
    "    dri_series.dropna(inplace=True)\n",
    "\n",
    "    # 5. Return the final Series\n",
    "    return dri_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,

   "id": "1163d5bd-3641-4cad-837a-982f5f3eec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dietary recommendations (RDA) for Female_endurance_athlete\n",
      "Nutrient\n",
      "Energy            2800.0\n",
      "Protein             80.0\n",
      "Carbohydrate       488.0\n",
      "Dietary Fiber       28.0\n",
      "Linoleic Acid       12.0\n",
      "Linolenic Acid       1.1\n",
      "Calcium           1000.0\n",
      "Iron                22.0\n",
      "Magnesium          310.0\n",
      "Phosphorus         700.0\n",
      "Potassium         4700.0\n",
      "Zinc                 8.0\n",
      "Copper               0.9\n",
      "Selenium            55.0\n",
      "Vitamin A          700.0\n",
      "Vitamin E           15.0\n",
      "Vitamin D           25.0\n",
      "Vitamin C           75.0\n",
      "Thiamin              1.1\n",
      "Riboflavin           1.1\n",
      "Niacin              14.0\n",
      "Vitamin B6           1.3\n",
      "Vitamin B12          2.4\n",
      "Choline            425.0\n",
      "Vitamin K           90.0\n",
      "Folate             400.0\n",
      "Name: Female_endurance_athlete, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#example of get_population_dri function\n",
    "\n",
    "'''\n",
    "select population from \n",
    "['Female_19_30', 'Female_endurance_athlete', 'Male_19_30', 'Male_endurance_athlete']\n",
    "'''\n",
    "\n",
    "population = \"Female_endurance_athlete\"\n",
    "dri_for_female_19_30 = get_population_dri(population, rda)\n",
    "\n",
    "print(\"Dietary recommendations (RDA) for\", population)\n",
    "print(dri_for_female_19_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,

   "id": "e72434c7-d3e1-4678-9dce-7de49cf87b77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linprog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#test of function to optimize all of code\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmin_cost_diet_with_bmin_bmax_and_prints\u001b[39m(\n\u001b[1;32m      3\u001b[0m     group: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      4\u001b[0m     rda: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[1;32m      5\u001b[0m     df_vegan: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[1;32m      6\u001b[0m     prices: pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[0;32m----> 7\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mlinprog\u001b[49m:\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# 1) Create lower (bmin) and upper (bmax) bounds for the chosen group\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#    using rows in rda where Constraint Type is RDA or AI.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     bmin \u001b[38;5;241m=\u001b[39m rda\u001b[38;5;241m.\u001b[39mloc[rda[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstraint Type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]), group]\n\u001b[1;32m     12\u001b[0m     bmax \u001b[38;5;241m=\u001b[39m rda\u001b[38;5;241m.\u001b[39mloc[rda[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstraint Type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]), group]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linprog' is not defined"
     ]
    }
   ],
   "source": [
    "#test of function to optimize all of code\n",
    "from scipy.optimize import linprog\n",
    "def min_cost_diet_with_bmin_bmax_and_prints(\n",
    "    group: str,\n",
    "    rda: pd.DataFrame,\n",
    "    df_vegan: pd.DataFrame,\n",
    "    prices: pd.DataFrame\n",
    ") -> linprog:\n",
    "\n",
    "    # 1) Create lower (bmin) and upper (bmax) bounds for the chosen group\n",
    "    #    using rows in rda where Constraint Type is RDA or AI.\n",
    "    bmin = rda.loc[rda[\"Constraint Type\"].isin([\"RDA\", \"AI\"]), group]\n",
    "    bmax = rda.loc[rda[\"Constraint Type\"].isin([\"RDA\", \"AI\"]), group]\n",
    "\n",
    "    # Reindex so they have the same nutrients\n",
    "    bmin = bmin.reindex(bmax.index).dropna(how=\"all\")\n",
    "    bmax = bmax.reindex(bmin.index).dropna(how=\"all\")\n",
    "\n",
    "    # 2) Intersect df_vegan & prices to ensure matching foods\n",
    "    common_recipes = df_vegan.index.intersection(prices.index)\n",
    "    df_vegan = df_vegan.loc[common_recipes]\n",
    "    prices = prices.loc[common_recipes]\n",
    "\n",
    "    # 3) Build the \">= bmin\" constraints\n",
    "    nutrients = bmin.index.tolist()\n",
    "    for nut in nutrients:\n",
    "        if nut not in df_vegan.columns:\n",
    "            raise ValueError(f\"Nutrient '{nut}' not found in df_vegan columns.\")\n",
    "\n",
    "    # Each row in df_vegan is a food; columns are nutrients => shape: (n_foods, n_nutrients)\n",
    "    A_bmin = df_vegan[nutrients].to_numpy()\n",
    "\n",
    "    # Convert >= to <= by multiplying by -1\n",
    "    A_ub = -A_bmin.T  # shape: (n_nutrients, n_foods)\n",
    "    b_ub = -bmin.values  # shape: (n_nutrients,)\n",
    "\n",
    "    # 4) Build the cost vector\n",
    "    if \"price\" not in prices.columns:\n",
    "        raise ValueError(\"The 'prices' DataFrame must have a 'price' column.\")\n",
    "    cost_vector = prices[\"price\"].to_numpy()  # shape: (n_foods,)\n",
    "\n",
    "    # Each food's serving >= 0\n",
    "    bounds = [(0, None)] * len(df_vegan)\n",
    "\n",
    "    # 5) Solve the linear program\n",
    "    tol = 1e-6  # treat solution values smaller than this as zero\n",
    "    result = linprog(\n",
    "        c=cost_vector,\n",
    "        A_ub=A_ub,\n",
    "        b_ub=b_ub,\n",
    "        bounds=bounds,\n",
    "        method=\"highs\",\n",
    "        options={\"tol\": tol}\n",
    "    )\n",
    "\n",
    "    if not result.success:\n",
    "        raise RuntimeError(f\"Linear program failed: {result.message}\")\n",
    "\n",
    "    # 6) Print results in your screenshot style\n",
    "    print(f\"Cost of diet for a vegan {group} is ${result.fun:.2f} per day.\\n\")\n",
    "\n",
    "    # Build a Series for the solution\n",
    "    diet = pd.Series(result.x, index=prices.index, name=\"servings\")\n",
    "\n",
    "    # Print \"100s of grams/mL\" if 1 serving ~ 100 g/mL\n",
    "    diet_100 = (diet * 100).round(2)\n",
    "    print(f\"\\nAs a vegan {group}, you'll be eating (in 100s of grams or milliliters):\\n\")\n",
    "    print(diet_100[diet_100 > 0.01])\n",
    "\n",
    "    # Return the entire solver result for further inspection\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 44,
   "id": "6bd7ca68-18a8-4880-892a-51163f4e7ad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'min_cost_diet_with_remapped_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFemale_endurance_athlete\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m servings_series \u001b[38;5;241m=\u001b[39m \u001b[43mmin_cost_diet_with_remapped_names\u001b[49m(\n\u001b[1;32m      3\u001b[0m     population\u001b[38;5;241m=\u001b[39mpopulation,\n\u001b[1;32m      4\u001b[0m     rda\u001b[38;5;241m=\u001b[39mrda,\n\u001b[1;32m      5\u001b[0m     df_vegan\u001b[38;5;241m=\u001b[39mdf_vegan,\n\u001b[1;32m      6\u001b[0m     prices\u001b[38;5;241m=\u001b[39mprices,\n\u001b[1;32m      7\u001b[0m     name_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecipe\u001b[39m\u001b[38;5;124m\"\u001b[39m   \n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'min_cost_diet_with_remapped_names' is not defined"
     ]
    }
   ],
   "source": [
    "population = \"Female_endurance_athlete\"\n",
    "servings_series = min_cost_diet_with_remapped_names(\n",
    "    population=population,\n",
    "    rda=rda,\n",
    "    df_vegan=df_vegan,\n",
    "    prices=prices,\n",
    "    name_column=\"recipe\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b42bc-77d3-49d1-a8bf-0632622d07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Installations\n",
    "import pandas as pd\n",
    "import os\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2b355-c94e-45a2-ba86-6746437711f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/jovyan/Project2/CPI/food_affordability_CA.xls'\n",
    "affordability_CA = pd.read_excel(file_path)\n",
    "affordability_CA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d145e-75dd-4680-85c8-17c9452c3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regional CPI ##\n",
    "\n",
    "The followings are the census divisions: \n",
    "New England, Middle Atlantic, East North Central, West North Central, South Atlantic, East South Central, West South Central, Mountain, and  Pacific. Each dataframe has the CPI for each census region with the monthly CPI changes as well as annual and first half and second half. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72896a5-18bd-4517-bbc1-39848ce5aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the file path\n",
    "file_path_1 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_EastSouthCentral.csv'\n",
    "file_path_2 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_MiddleAtlantic.csv'\n",
    "file_path_3 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_East_North_Central.csv'\n",
    "file_path_4 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_Mountain.csv'\n",
    "file_path_5 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_NewEngland.csv'\n",
    "file_path_6 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_Pacific.csv'\n",
    "file_path_7 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_SouthAtlantic.csv'\n",
    "file_path_8 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_WestNorthCentral.csv'\n",
    "file_path_9 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_WestSouthCentral.csv'\n",
    "\n",
    "#individual files for each census regions\n",
    "CPI_East_South_Central = pd.read_csv(file_path_1)\n",
    "CPI_Middle_Atlantic = pd.read_csv(file_path_2)\n",
    "CPI_East_North_Central = pd.read_csv(file_path_3)\n",
    "CPI_Mountain = pd.read_csv(file_path_4)\n",
    "CPI_NewEngland = pd.read_csv(file_path_5)\n",
    "CPI_Pacific = pd.read_csv(file_path_6)\n",
    "CPI_South_Atlantic = pd.read_csv(file_path_7)\n",
    "CPI_West_North_Central = pd.read_csv(file_path_8)\n",
    "CPI_West_South_Central = pd.read_csv(file_path_9)\n",
    "\n",
    "#example of a dataframe\n",
    "CPI_East_South_Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267e9ab-df1a-429e-9bb1-0f5d371a8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the Dataframe to make it easier to work with ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be19427-5a7b-498a-b29e-4cab9cebc348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of DataFrames\n",
    "cpi_dfs = {\n",
    "    \"CPI_East_South_Central\": CPI_East_South_Central,\n",
    "    \"CPI_Middle_Atlantic\": CPI_Middle_Atlantic,\n",
    "    \"CPI_East_North_Central\": CPI_East_North_Central,\n",
    "    \"CPI_Mountain\": CPI_Mountain,\n",
    "    \"CPI_NewEngland\": CPI_NewEngland,\n",
    "    \"CPI_Pacific\": CPI_Pacific,\n",
    "    \"CPI_South_Atlantic\": CPI_South_Atlantic,\n",
    "    \"CPI_West_North_Central\": CPI_West_North_Central,\n",
    "    \"CPI_West_South_Central\": CPI_West_South_Central\n",
    "}\n",
    "\n",
    "# Loop through all DataFrames and set \"Year\" as the index\n",
    "for name, df in cpi_dfs.items():\n",
    "    if \"Year\" in df.columns:  # Check if \"Year\" column exists\n",
    "        df.set_index(\"Year\", inplace=True)\n",
    "\n",
    "# Now all DataFrames have \"Year\" as the index\n",
    "\n",
    "CPI_East_North_Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef55f10-86d7-43b2-9cbb-5ab09d18e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "2017 is the base year for CPI calculation for all the dataframe. We will use the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bf610-bdee-4cce-a72d-10cd1876a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating Adjusted Cost of Minimum Diet Using CPI\n",
    "\n",
    "To determine the cost of a minimum diet for each region, we use the Consumer Price Index (CPI) as an adjustment factor. The formula is given by:\n",
    "\n",
    "$$\n",
    "\\text{Adjusted Cost}_{\\text{region}} = \\text{Base Cost} \\times \\frac{\\text{CPI}_{\\text{region}}}{\\text{CPI}_{\\text{base}}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **$\\text{Adjusted Cost}_{\\text{region}}$** is the estimated cost of the minimum diet in the specific region.\n",
    "- **$\\text{Base Cost}$** is the reference cost of the minimum diet (typically from a standard region or dataset).\n",
    "- **$\\text{CPI}_{\\text{region}}$** is the Consumer Price Index for the specific region.\n",
    "- **$\\text{CPI}_{\\text{base}}$** is the CPI of the reference region.\n",
    "\n",
    "This method adjusts the base cost according to regional price variations, ensuring that the diet cost reflects local economic conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4df2e5-61a4-4994-80eb-c8c8f9e2b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change the variable name and structure AFTER sorting out the FINAL files ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9665bf-4d43-4a39-8d0d-938cc379540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_price_vegan_m_endurance_ath = result.fun\n",
    "diet_vegan_m_endurance_ath = diet[diet >= tol]\n",
    "min_price_vegan_m_endurance_ath\n",
    "#diet_vegan_m_endurance_ath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d1ff0-c94e-439a-a52f-5e37ee809b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Calculated Adjusted Minimum Cost Diet as a Dataframe ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216eff6-77d9-47a3-921c-9a82a199db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPI_East_North_Central.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cfbfd2-977b-4d68-a50d-ad88a2404614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary containing all CPI DataFrames\n",
    "cpi_dfs = {\n",
    "    \"East_South_Central\": CPI_East_South_Central,\n",
    "    \"Middle_Atlantic\": CPI_Middle_Atlantic,\n",
    "    \"East_North_Central\": CPI_East_North_Central,\n",
    "    \"Mountain\": CPI_Mountain,\n",
    "    \"NewEngland\": CPI_NewEngland,\n",
    "    \"Pacific\": CPI_Pacific,\n",
    "    \"South_Atlantic\": CPI_South_Atlantic,\n",
    "    \"West_North_Central\": CPI_West_North_Central,\n",
    "    \"West_South_Central\": CPI_West_South_Central\n",
    "}\n",
    "\n",
    "# Define base year and minimum cost of diet\n",
    "base_year = 2017  #  CPI base year for all census region\n",
    "min_price_vegan_m_endurance_ath = min_price_vegan_m_endurance_ath \n",
    "\n",
    "# Create an empty list to store results\n",
    "adjusted_cost_data = []\n",
    "\n",
    "# Loop through each region's CPI data\n",
    "for region, df in cpi_dfs.items():\n",
    "    # Ensure Year is the index and fetch CPI values\n",
    "    if base_year in df.index and 2024 in df.index:\n",
    "        cpi_base = df.loc[base_year, \"Dec\"]  # CPI for base year is given in December\n",
    "        cpi_latest = df.loc[2024, \"Annual\"]  # CPI for latest available year which is 2024\n",
    "        # Calculate adjusted diet cost\n",
    "        adjusted_cost = min_price_vegan_m_endurance_ath * (cpi_latest / cpi_base)\n",
    "        \n",
    "        # Append results\n",
    "        adjusted_cost_data.append([region, adjusted_cost])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "adjusted_cost_df = pd.DataFrame(adjusted_cost_data, columns=[\"Region\", \"Adjusted_Cost\"])\n",
    "\n",
    "# Display the DataFrame in Jupyter Notebook\n",
    "display(adjusted_cost_df)  # For Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49e1cc-c2ef-4192-8efb-a877a15f4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_cost_by_cpi(min_price, cpi_dfs, base_year=2017, latest_year=2024):\n",
    "    \"\"\"\n",
    "    Adjusts a base diet cost using CPI data from multiple regions and returns\n",
    "    a DataFrame with the region name and adjusted costs.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    min_price : float\n",
    "        Minimum diet cost to be adjusted (e.g., min_price_vegan_m_endurance_ath)\n",
    "    cpi_dfs : dict of pd.DataFrame\n",
    "        Dictionary keyed by region. Each value is a DataFrame with CPI data for multiple years,\n",
    "        where the DataFrame index is years, and includes columns like 'Dec' and 'Annual'\n",
    "    base_year : int, default 2017\n",
    "        The year in the DataFrame(s) to use as a CPI base.\n",
    "    latest_year : int, default 2024\n",
    "        The year in the DataFrame(s) to use as the CPI for the latest adjustment.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with columns [\"Region\", \"Adjusted_Cost\"] where \"Region\" is the key\n",
    "        from the dictionary, and \"Adjusted_Cost\" is the adjusted cost for that region.\n",
    "    \"\"\"\n",
    "    adjusted_cost_data = []\n",
    "\n",
    "    for region, df in cpi_dfs.items():\n",
    "        # We check both the base and latest years are present in the index\n",
    "        if base_year in df.index and latest_year in df.index:\n",
    "            cpi_base = df.loc[base_year, \"Dec\"]\n",
    "            cpi_latest = df.loc[latest_year, \"Annual\"]\n",
    "            \n",
    "            # Calculate the adjusted cost\n",
    "            adjusted_cost = min_price * (cpi_latest / cpi_base)\n",
    "            \n",
    "            # Append to our list of results\n",
    "            adjusted_cost_data.append([region, adjusted_cost])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    adjusted_cost_df = pd.DataFrame(adjusted_cost_data, columns=[\"Region\", \"Adjusted_Cost\"])\n",
    "\n",
    "    return adjusted_cost_df\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

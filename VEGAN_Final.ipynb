{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a75984ca-08f3-4d38-9166-79d441c22d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eep153_tools in /srv/conda/lib/python3.11/site-packages (0.12.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python_gnupg in /srv/conda/lib/python3.11/site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gspread_pandas in /srv/conda/lib/python3.11/site-packages (3.3.0)\n",
      "Requirement already satisfied: gspread<6,>=5.0.0 in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (5.12.4)\n",
      "Requirement already satisfied: pandas>=0.20.0 in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (2.2.3)\n",
      "Requirement already satisfied: decorator in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (5.1.1)\n",
      "Requirement already satisfied: google-auth in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /srv/conda/lib/python3.11/site-packages (from gspread_pandas) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /srv/conda/lib/python3.11/site-packages (from google-auth->gspread_pandas) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /srv/conda/lib/python3.11/site-packages (from google-auth-oauthlib->gspread_pandas) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /srv/conda/lib/python3.11/site-packages (from pandas>=0.20.0->gspread_pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/lib/python3.11/site-packages (from pandas>=0.20.0->gspread_pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/lib/python3.11/site-packages (from pandas>=0.20.0->gspread_pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /srv/conda/lib/python3.11/site-packages (from pandas>=0.20.0->gspread_pandas) (2025.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /srv/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth->gspread_pandas) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->gspread_pandas) (1.17.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /srv/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /srv/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/lib/python3.11/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->gspread_pandas) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install eep153_tools\n",
    "%pip install python_gnupg\n",
    "%pip install -U gspread_pandas\n",
    "#load in file from class\n",
    "def format_id(id,zeropadding=0):\n",
    "    \"\"\"Nice string format for any id, string or numeric.\n",
    "\n",
    "    Optional zeropadding parameter takes an integer\n",
    "    formats as {id:0z} where\n",
    "    \"\"\"\n",
    "    if pd.isnull(id) or id in ['','.']: return None\n",
    "\n",
    "    try:  # If numeric, return as string int\n",
    "        return ('%d' % id).zfill(zeropadding)\n",
    "    except TypeError:  # Not numeric\n",
    "        return id.split('.')[0].strip().zfill(zeropadding)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "data_url = \"https://docs.google.com/spreadsheets/d/1GTo423_gUJe1Von9jypWAbC0zSQ7WGegAWPuRi7eJAI/edit?gid=1410082681#gid=1410082681\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7f10138f-ba5d-4e3c-ac9b-3220baf9f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_foodcode</th>\n",
       "      <th>recipe</th>\n",
       "      <th>ingred_code</th>\n",
       "      <th>ingred_desc</th>\n",
       "      <th>ingred_wt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11340000</td>\n",
       "      <td>Imitation milk, non-soy, sweetened</td>\n",
       "      <td>43543</td>\n",
       "      <td>Milk, imitation, non-soy</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11460150</td>\n",
       "      <td>Yogurt, frozen, NS as to flavor, lowfat milk</td>\n",
       "      <td>1298</td>\n",
       "      <td>Yogurt, frozen, flavors other than chocolate, ...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>1117</td>\n",
       "      <td>Yogurt, plain, low fat, 12 grams protein per 8...</td>\n",
       "      <td>81.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>19166</td>\n",
       "      <td>Cocoa, dry powder, unsweetened, processed with...</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>19335</td>\n",
       "      <td>Sugars, granulated</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_foodcode                                        recipe ingred_code  \\\n",
       "0        11340000            Imitation milk, non-soy, sweetened       43543   \n",
       "1        11460150  Yogurt, frozen, NS as to flavor, lowfat milk        1298   \n",
       "2        11460160        Yogurt, frozen, chocolate, lowfat milk        1117   \n",
       "3        11460160        Yogurt, frozen, chocolate, lowfat milk       19166   \n",
       "4        11460160        Yogurt, frozen, chocolate, lowfat milk       19335   \n",
       "\n",
       "                                         ingred_desc  ingred_wt  \n",
       "0                           Milk, imitation, non-soy      100.0  \n",
       "1  Yogurt, frozen, flavors other than chocolate, ...      100.0  \n",
       "2  Yogurt, plain, low fat, 12 grams protein per 8...       81.8  \n",
       "3  Cocoa, dry powder, unsweetened, processed with...        5.2  \n",
       "4                                 Sugars, granulated       13.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from eep153_tools.sheets import read_sheets\n",
    "\n",
    "#create recipes df\n",
    "recipes = read_sheets(data_url, sheet=\"recipes\")\n",
    "recipes = (recipes\n",
    "           .assign(parent_foodcode = lambda df: df[\"parent_foodcode\"].apply(format_id),\n",
    "                   ingred_code = lambda df: df[\"ingred_code\"].apply(format_id))\n",
    "           .rename(columns={\"parent_desc\": \"recipe\"}))\n",
    "recipes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c4f37ab6-a060-4139-b69d-ad6c52cf40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of non-vegan keywords AND non-natural foods keywords (including frozen, processed, etc).\n",
    "NON_VEGAN_KEYWORDS = [\n",
    "    \"beef\", \"pork\", \"chicken\", \"turkey\", \"fish\", \"seafood\", \"shellfish\", \"shrimp\", \"crab\",\"crabs\",\n",
    "    \"lamb\", \"goat\", \"duck\", \"goose\", \"tuna\", \"salmon\", \"cod\", \"bacon\", \"ham\",\n",
    "    \"shellfish\", \"lobster\", \"mussels\", \"oysters\", \"scallops\", \"octopus\", \"eel\",\n",
    "    \"organ meat\", \"milk\",\"Eggnog\" \"cheese\", \"butter\", \"cream\",\"ice cream\", \"yogurt\", \"whey\",\n",
    "    \"casein\", \"lactose\", \"ghee\", \"buttermilk\", \"egg\", \"eggs\", \"mayo\", \"mayonnaise\", \"albumen\",\n",
    "    \"albumin\", \"lysozyme\", \"ovomucoid\", \"ovomucin\", \"ovovitellin\", \"honey\",\n",
    "    \"bee pollen\", \"royal jelly\", \"propolis\", \"shellac\", \"confectioner’s glaze\",\n",
    "    \"carmine\", \"cochineal\", \"lard\", \"tallow\", \"suet\", \"gelatin\", \"collagen\",\n",
    "    \"isinglass\", \"bone broth\", \"bone stock\", \"fish sauce\", \"oyster sauce\",\n",
    "    \"shrimp paste\", \"worcestershire sauce\", \"anchovies\", \"rennet\", \"pepsin\",\n",
    "    \"bone char\", \"vitamin d3\", \"lanolin\", \"omega-3 fish oil\", \"caseinate\",\n",
    "    \"lecithin (egg)\", \"cysteine\", \"l-cysteine\", \"glycerin (animal)\",\n",
    "    \"glycerol (animal)\", \"stearic acid (animal)\", \"tallowate\", \"sodium tallowate\",\n",
    "    \"capric acid\", \"caprylic acid\", \"cheese\", \"pudding\", \"processed\", \"veal\",'sirloin', \"steak\", \"animal\",\n",
    "    \"Custard\", \"Mousse\", \"chocolate\", \"Meatballs\", \"meat\", \"Gravy\", \"poultry\",\"baby\", \"frozen\", 'dairy', 'lump',\"peas\",\"school\", \"mix\"\n",
    "]\n",
    "\n",
    "#this partal match: \"milkshake\" or \"eggroll\" will get flagged (since \"milk\" or \"egg\" is in the keyword list).\n",
    "NON_VEGAN_PATTERN = re.compile(\n",
    "    '|'.join(map(re.escape, NON_VEGAN_KEYWORDS)),\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def filter_vegan_ingredients(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 1) Convert to string, lowercase, remove punctuation\n",
    "    df[\"recipe\"] = df[\"recipe\"].astype(str).str.lower().fillna(\"\")\n",
    "    df[\"recipe\"] = df[\"recipe\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "    df[\"ingred_desc\"] = df[\"ingred_desc\"].astype(str).str.lower().fillna(\"\")\n",
    "    df[\"ingred_desc\"] = df[\"ingred_desc\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "    # 2) Create a mask for rows that do NOT contain non-vegan keywords\n",
    "    mask = ~(df[\"recipe\"].str.contains(NON_VEGAN_PATTERN, na=False, regex=True) |\n",
    "             df[\"ingred_desc\"].str.contains(NON_VEGAN_PATTERN, na=False, regex=True))\n",
    "\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a72e0efe-81c5-4844-b116-3ff371adc7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10823, 5)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_recipes = filter_vegan_ingredients(recipes)\n",
    "vegan_recipes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "75ff8ffe-65da-40bf-90e6-a083f7c9732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingred_code</th>\n",
       "      <th>Ingredient description</th>\n",
       "      <th>Capric acid</th>\n",
       "      <th>Lauric acid</th>\n",
       "      <th>Myristic acid</th>\n",
       "      <th>Palmitic acid</th>\n",
       "      <th>Palmitoleic acid</th>\n",
       "      <th>Stearic acid</th>\n",
       "      <th>Oleic acid</th>\n",
       "      <th>Linoleic Acid</th>\n",
       "      <th>...</th>\n",
       "      <th>Vitamin B12</th>\n",
       "      <th>Vitamin B-12, added</th>\n",
       "      <th>Vitamin B6</th>\n",
       "      <th>Vitamin C</th>\n",
       "      <th>Vitamin D</th>\n",
       "      <th>Vitamin E</th>\n",
       "      <th>Vitamin E, added</th>\n",
       "      <th>Vitamin K</th>\n",
       "      <th>Water</th>\n",
       "      <th>Zinc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>2.529</td>\n",
       "      <td>2.587</td>\n",
       "      <td>7.436</td>\n",
       "      <td>21.697</td>\n",
       "      <td>0.961</td>\n",
       "      <td>9.999</td>\n",
       "      <td>19.961</td>\n",
       "      <td>2.728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.87</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>2.039</td>\n",
       "      <td>2.354</td>\n",
       "      <td>7.515</td>\n",
       "      <td>20.531</td>\n",
       "      <td>1.417</td>\n",
       "      <td>7.649</td>\n",
       "      <td>17.370</td>\n",
       "      <td>2.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.793</td>\n",
       "      <td>10.005</td>\n",
       "      <td>26.166</td>\n",
       "      <td>2.228</td>\n",
       "      <td>12.056</td>\n",
       "      <td>25.026</td>\n",
       "      <td>2.247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.491</td>\n",
       "      <td>3.301</td>\n",
       "      <td>9.153</td>\n",
       "      <td>0.816</td>\n",
       "      <td>3.235</td>\n",
       "      <td>6.622</td>\n",
       "      <td>0.536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>42.41</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.482</td>\n",
       "      <td>3.227</td>\n",
       "      <td>8.655</td>\n",
       "      <td>0.817</td>\n",
       "      <td>3.455</td>\n",
       "      <td>7.401</td>\n",
       "      <td>0.491</td>\n",
       "      <td>...</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>41.11</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ingred_code      Ingredient description  Capric acid  Lauric acid  \\\n",
       "0        1001              Butter, salted        2.529        2.587   \n",
       "1        1002  Butter, whipped, with salt        2.039        2.354   \n",
       "2        1003       Butter oil, anhydrous        2.495        2.793   \n",
       "3        1004                Cheese, blue        0.601        0.491   \n",
       "4        1005               Cheese, brick        0.585        0.482   \n",
       "\n",
       "   Myristic acid  Palmitic acid  Palmitoleic acid  Stearic acid  Oleic acid  \\\n",
       "0          7.436         21.697             0.961         9.999      19.961   \n",
       "1          7.515         20.531             1.417         7.649      17.370   \n",
       "2         10.005         26.166             2.228        12.056      25.026   \n",
       "3          3.301          9.153             0.816         3.235       6.622   \n",
       "4          3.227          8.655             0.817         3.455       7.401   \n",
       "\n",
       "   Linoleic Acid  ...  Vitamin B12  Vitamin B-12, added  Vitamin B6  \\\n",
       "0          2.728  ...         0.17                  0.0       0.003   \n",
       "1          2.713  ...         0.07                  0.0       0.008   \n",
       "2          2.247  ...         0.01                  0.0       0.001   \n",
       "3          0.536  ...         1.22                  0.0       0.166   \n",
       "4          0.491  ...         1.26                  0.0       0.065   \n",
       "\n",
       "   Vitamin C  Vitamin D  Vitamin E  Vitamin E, added  Vitamin K  Water  Zinc  \n",
       "0        0.0        0.0       2.32               0.0        7.0  15.87  0.09  \n",
       "1        0.0        0.0       1.37               0.0        4.6  16.72  0.05  \n",
       "2        0.0        0.0       2.80               0.0        8.6   0.24  0.01  \n",
       "3        0.0        0.5       0.25               0.0        2.4  42.41  2.66  \n",
       "4        0.0        0.5       0.26               0.0        2.5  41.11  2.60  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe_id\n",
      "11115400    kefir ns as to fat content\n",
      "11440060                  tzatziki dip\n",
      "11551050             licuado or batido\n",
      "11553100            fruit smoothie nfs\n",
      "11710000            infant formula nfs\n",
      "Name: recipe, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_160/3073712158.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vegan_recipes['ingred_wt'] = vegan_recipes['ingred_wt']/vegan_recipes.groupby(['parent_foodcode'])['ingred_wt'].transform(\"sum\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3824, 66)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start copying code from mini lecture VEGAN\n",
    "\n",
    "#create nutrition df\n",
    "nutrition = (read_sheets(data_url, sheet=\"nutrients\")\n",
    "             .assign(ingred_code = lambda df: df[\"ingred_code\"].apply(format_id)))\n",
    "\n",
    "display(nutrition.head())\n",
    "nutrition.columns\n",
    "nutrition.shape\n",
    "\n",
    "\n",
    "\n",
    "# normalize weights to percentage terms. \n",
    "vegan_recipes['ingred_wt'] = vegan_recipes['ingred_wt']/vegan_recipes.groupby(['parent_foodcode'])['ingred_wt'].transform(\"sum\")\n",
    "\n",
    "# we're going to extend the recipes data frame to include the nutrient profiles of its ingredients (in 100g)\n",
    "df_vegan = vegan_recipes.merge(nutrition, how=\"left\", on=\"ingred_code\")\n",
    "\n",
    "# multiply all nutrients per 100g of an ingredient by the weight of that ingredient in a recipe.\n",
    "numeric_cols = list(df_vegan.select_dtypes(include=[\"number\"]).columns)\n",
    "numeric_cols.remove(\"ingred_wt\")\n",
    "df_vegan[numeric_cols] = df_vegan[numeric_cols].mul(df_vegan[\"ingred_wt\"], axis=0)\n",
    "\n",
    "# sum nutrients of food codes (over the multiple ingredients)\n",
    "# python tip: one can merge dictionaries dict1 dict2 using **, that is: dict_merge = {**dict1, **dict2}. The ** effectively \"unpacks\" the key value pairs in each dictionary\n",
    "df_vegan = df_vegan.groupby('parent_foodcode').agg({**{col: \"sum\" for col in numeric_cols},\n",
    "                                        \"recipe\": \"first\"})\n",
    "\n",
    "df_vegan.index.name = \"recipe_id\"\n",
    "\n",
    "food_names = df_vegan[\"recipe\"]\n",
    "print(food_names.head())\n",
    "df_vegan.head()\n",
    "df_vegan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "352dfbc1-6bec-4f3e-8e5b-36b7b825f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2011/2012', '2013/2014', '2015/2016', '2017/2018'], dtype='object', name='year')\n",
      "We have prices for 4435 unique recipes (FNDDS food codes)\n"
     ]
    }
   ],
   "source": [
    "prices = read_sheets(data_url, sheet=\"prices\")[[\"food_code\", \"year\", \"price\"]]\n",
    "\n",
    "prices[\"food_code\"] = prices[\"food_code\"].apply(format_id)\n",
    "\n",
    "prices = prices.set_index([\"year\", \"food_code\"])\n",
    "print(prices.index.levels[0])\n",
    "\n",
    "# we'll focus on the latest price data\n",
    "prices = prices.xs(\"2017/2018\", level=\"year\")\n",
    "\n",
    "# drop rows of prices where the price is \"NA\"\n",
    "prices = prices.dropna(subset=\"price\")\n",
    "\n",
    "print(f\"We have prices for {prices.shape[0]} unique recipes (FNDDS food codes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bc91010d-3430-4537-93f8-3f02896d0a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Nutrient Type', 'Unit', 'Constraint Type', 'Female_19_30',\n",
       "        'Female_endurance_athlete', 'Male_19_30', 'Male_endurance_athlete'],\n",
       "       dtype='object'),\n",
       "               Nutrient Type  Unit Constraint Type  Female_19_30  \\\n",
       " Nutrient                                                          \n",
       " Energy                Macro  kcal             RDA        2000.0   \n",
       " Protein               Macro     g             RDA          46.0   \n",
       " Carbohydrate          Macro     g             RDA         130.0   \n",
       " Dietary Fiber         Macro     g             RDA          28.0   \n",
       " Linoleic Acid         Macro     g              AI          12.0   \n",
       " \n",
       "                Female_endurance_athlete  Male_19_30  Male_endurance_athlete  \n",
       " Nutrient                                                                     \n",
       " Energy                           2800.0      2400.0                  3500.0  \n",
       " Protein                            80.0        56.0                   112.0  \n",
       " Carbohydrate                      488.0       130.0                   560.0  \n",
       " Dietary Fiber                      28.0        33.6                    38.0  \n",
       " Linoleic Acid                      12.0        17.0                    17.0  ,\n",
       "               Nutrient Type  Unit Constraint Type  Female_19_30  \\\n",
       " Nutrient                                                          \n",
       " Energy                Macro  kcal             RDA        2000.0   \n",
       " Protein               Macro     g             RDA          46.0   \n",
       " Carbohydrate          Macro     g             RDA         130.0   \n",
       " Dietary Fiber         Macro     g             RDA          28.0   \n",
       " Linoleic Acid         Macro     g              AI          12.0   \n",
       " \n",
       "                Female_endurance_athlete  Male_19_30  Male_endurance_athlete  \n",
       " Nutrient                                                                     \n",
       " Energy                           2800.0      2400.0                  3500.0  \n",
       " Protein                            80.0        56.0                   112.0  \n",
       " Carbohydrate                      488.0       130.0                   560.0  \n",
       " Dietary Fiber                      28.0        33.6                    38.0  \n",
       " Linoleic Acid                      12.0        17.0                    17.0  )"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add diet requirements\n",
    "\n",
    "rda = read_sheets(data_url, sheet=\"rda\")\n",
    "\n",
    "rda = rda.set_index(\"Nutrient\")\n",
    "rda_min = rda[rda[\"Constraint Type\"].isin([\"RDA\", \"AI\"])].copy()\n",
    "\n",
    "\n",
    "rda.columns, rda.head(), rda_min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fdd09b5e-c13f-4749-9dfd-09c22a2ff588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       price\n",
      "kefir ns as to fat content                          0.345625\n",
      "tzatziki dip                                        1.217789\n",
      "licuado or batido                                   0.189099\n",
      "fruit smoothie nfs                                  0.462558\n",
      "infant formula readytofeed similac expert care ...  1.074909\n",
      "                 11115400  11440060  11551050  11553100 11710051 11710055  \\\n",
      "Capric acid        0.0195  0.005673   0.00048  0.000813    0.689    0.689   \n",
      "Lauric acid         0.026  0.000273  0.000959  0.001626    0.023    0.023   \n",
      "Myristic acid      0.0945  0.000545  0.000959  0.001626    0.007    0.007   \n",
      "Palmitic acid      0.2805    5.7604  0.053557  0.083665    0.137    0.137   \n",
      "Palmitoleic acid   0.0185  0.638909  0.005183  0.008129    0.003    0.003   \n",
      "\n",
      "                  11710357  11710358 11710377 11710378  ... 95311000 95312410  \\\n",
      "Capric acid       0.078597  0.078597      0.0      0.0  ...      0.0      0.0   \n",
      "Lauric acid       0.486647  0.486647      0.0      0.0  ...      0.0      0.0   \n",
      "Myristic acid     0.183183  0.183183      0.0      0.0  ...      0.0      0.0   \n",
      "Palmitic acid     0.258139  0.258139      0.0      0.0  ...      0.0      0.0   \n",
      "Palmitoleic acid  0.002386  0.002386      0.0      0.0  ...      0.0      0.0   \n",
      "\n",
      "                 95312560 95312600 95312700 95313200 95320200 95320500  \\\n",
      "Capric acid           0.0      0.0      0.0      0.0      0.0    0.001   \n",
      "Lauric acid           0.0      0.0      0.0      0.0      0.0    0.004   \n",
      "Myristic acid         0.0      0.0      0.0      0.0      0.0    0.001   \n",
      "Palmitic acid         0.0      0.0      0.0      0.0      0.0    0.001   \n",
      "Palmitoleic acid      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "                 95322200 95330100  \n",
      "Capric acid           0.0      0.0  \n",
      "Lauric acid           0.0      0.0  \n",
      "Myristic acid         0.0      0.0  \n",
      "Palmitic acid         0.0      0.0  \n",
      "Palmitoleic acid      0.0      0.0  \n",
      "\n",
      "[5 rows x 1794 columns]\n"
     ]
    }
   ],
   "source": [
    "common_recipes = df_vegan.index.intersection(prices.index)\n",
    "\n",
    "# python tip: given a list of indices, \"loc\" both subsets and sorts. \n",
    "df_vegan = df_vegan.loc[common_recipes]\n",
    "prices = prices.loc[common_recipes]\n",
    "\n",
    "# lets remap the price dataframe index to be the actual food names.\n",
    "prices.index = prices.index.map(food_names)\n",
    "\n",
    "A_all = df_vegan.T\n",
    "\n",
    "print(prices.head())\n",
    "print(A_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8aa5cc1b-2ade-49a6-8861-53bbad6acb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmin.shape=(26,)\n",
      "Amin.shape=(26, 1794)\n",
      "bmax.shape=(1,)\n",
      "Amax.shape=(1, 1794)\n",
      "b.shape=(27,)\n",
      "A.shape=(27, 1794)\n",
      "prices.shape=(1794, 1)\n"
     ]
    }
   ],
   "source": [
    "# pick a demographic (column from rda dataframe)\n",
    "'''\n",
    "select from \n",
    "['Female_19_30', 'Female_endurance_athlete', 'Male_19_30', 'Male_endurance_athlete']\n",
    "'''\n",
    "group = 'Male_19_30'\n",
    "\n",
    "# create lower bounds and upper bounds.\n",
    "bmin = rda.loc[rda['Constraint Type'].isin(['RDA', 'AI']), group]\n",
    "bmax = rda.loc[rda['Constraint Type'].isin(['UL']), group]\n",
    "\n",
    "# reindex ensures we only keep nutrients in bmin/bmax\n",
    "Amin = A_all.reindex(bmin.index).dropna(how='all')\n",
    "Amax = A_all.reindex(bmax.index).dropna(how='all')\n",
    "\n",
    "b = pd.concat([bmin, -bmax])\n",
    "A = pd.concat([Amin, -Amax])\n",
    "\n",
    "#python tip: by typing \"=\" after the variable name inside the curly braces, it formats the output so we don't have to write f\"variable = {variable}\"\n",
    "print(f\"{bmin.shape=}\")\n",
    "print(f\"{Amin.shape=}\")\n",
    "print(f\"{bmax.shape=}\")\n",
    "print(f\"{Amax.shape=}\")\n",
    "print(f\"{b.shape=}\")\n",
    "print(f\"{A.shape=}\")\n",
    "print(f\"{prices.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816cbc46-fdab-4cd3-8790-eb18e0995ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "46e58d04-887d-485a-8499-ed367f169c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  scipy.optimize import linprog as lp\n",
    "import numpy as np\n",
    "p = prices\n",
    "tol = 1e-6 # Numbers in solution smaller than this (in absolute value) treated as zeros\n",
    "result = lp(p, -A, -b, method='highs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3d688f20-3633-4c87-bb42-df3292ece5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of diet for a vegan Male_19_30 is $3.84 per day.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cost of diet for a vegan {group} is ${result.fun:.2f} per day.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "283b0494-ae26-4603-b191-5217f5c77df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of diet for a vegan Male_19_30 is $3.84 per day. \n",
      "\n",
      "As a vegan Male_19_30 you'll be eating (in 100s of grams or milliliters): \n",
      "\n",
      "peruvian beans from dried        2.16\n",
      "vermicelli made from soybeans    3.67\n",
      "peanuts unroasted                0.33\n",
      "cereal rice flakes               0.31\n",
      "cereal toasted oat               1.78\n",
      "beans and rice with tomatoes     6.40\n",
      "ripe plantain raw                0.86\n",
      "cilantro raw                     0.22\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# lets mess with the index on price df so they are recipe names not ids.\n",
    "\n",
    "# get the result x in a series with food names\n",
    "diet = pd.Series(result.x,index=prices.index)\n",
    "\n",
    "\n",
    "print(f\"Cost of diet for a vegan {group} is ${result.fun:.2f} per day. \\n\")\n",
    "\n",
    "print(f\"As a vegan {group} you'll be eating (in 100s of grams or milliliters): \\n\")\n",
    "\n",
    "print(round(diet[diet >= tol], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2050940d-120b-4f22-b903-95a91f40fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for deliverable [A] Dietary Reference Intakes\n",
    "\n",
    "#NEED TO ADD MORE categories into the Google sheet to make better, females, males of different ages, etc.\n",
    "def get_population_dri(population: str, rda_df: pd.DataFrame) -> pd.Series:\n",
    "    \n",
    "    # 1. Filter rows to only those where Constraint Type is RDA or AI\n",
    "    rda_filtered = rda_df[rda_df[\"Constraint Type\"].isin([\"RDA\", \"AI\"])].copy()\n",
    "\n",
    "    # 3. Extract the column for the chosen population as a Series\n",
    "    dri_series = rda_filtered[population]\n",
    "\n",
    "    # 4. Drop any rows that are NaN (just in case)\n",
    "    dri_series.dropna(inplace=True)\n",
    "\n",
    "    # 5. Return the final Series\n",
    "    return dri_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1163d5bd-3641-4cad-837a-982f5f3eec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dietary recommendations (RDA) for Male_endurance_athlete\n",
      "Nutrient\n",
      "Energy            3500.0\n",
      "Protein            112.0\n",
      "Carbohydrate       560.0\n",
      "Dietary Fiber       38.0\n",
      "Linoleic Acid       17.0\n",
      "Linolenic Acid       1.6\n",
      "Calcium           1000.0\n",
      "Iron                 8.0\n",
      "Magnesium          400.0\n",
      "Phosphorus         700.0\n",
      "Potassium         4700.0\n",
      "Zinc                11.0\n",
      "Copper               0.9\n",
      "Selenium            55.0\n",
      "Vitamin A          900.0\n",
      "Vitamin E           15.0\n",
      "Vitamin D           15.0\n",
      "Vitamin C           90.0\n",
      "Thiamin              1.3\n",
      "Riboflavin           1.9\n",
      "Niacin              29.0\n",
      "Vitamin B6           1.3\n",
      "Vitamin B12          2.4\n",
      "Choline            550.0\n",
      "Vitamin K          120.0\n",
      "Folate             400.0\n",
      "Name: Male_endurance_athlete, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#example of get_population_dri function\n",
    "\n",
    "'''\n",
    "select population from \n",
    "['Female_19_30', 'Female_endurance_athlete', 'Male_19_30', 'Male_endurance_athlete']\n",
    "'''\n",
    "\n",
    "population = \"Male_endurance_athlete\"\n",
    "dri_for_female_19_30 = get_population_dri(population, rda)\n",
    "\n",
    "print(\"Dietary recommendations (RDA) for\", population)\n",
    "print(dri_for_female_19_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e72434c7-d3e1-4678-9dce-7de49cf87b77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linprog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#test of function to optimize all of code\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmin_cost_diet_with_bmin_bmax_and_prints\u001b[39m(\n\u001b[1;32m      3\u001b[0m     group: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      4\u001b[0m     rda: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[1;32m      5\u001b[0m     df_vegan: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[1;32m      6\u001b[0m     prices: pd\u001b[38;5;241m.\u001b[39mDataFrame\n\u001b[0;32m----> 7\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mlinprog\u001b[49m:\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# 1) Create lower (bmin) and upper (bmax) bounds for the chosen group\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#    using rows in rda where Constraint Type is RDA or AI.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     bmin \u001b[38;5;241m=\u001b[39m rda\u001b[38;5;241m.\u001b[39mloc[rda[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstraint Type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]), group]\n\u001b[1;32m     12\u001b[0m     bmax \u001b[38;5;241m=\u001b[39m rda\u001b[38;5;241m.\u001b[39mloc[rda[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstraint Type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]), group]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linprog' is not defined"
     ]
    }
   ],
   "source": [
    "#test of function to optimize all of code\n",
    "def min_cost_diet_with_bmin_bmax_and_prints(\n",
    "    group: str,\n",
    "    rda: pd.DataFrame,\n",
    "    df_vegan: pd.DataFrame,\n",
    "    prices: pd.DataFrame\n",
    ") -> linprog:\n",
    "\n",
    "    # 1) Create lower (bmin) and upper (bmax) bounds for the chosen group\n",
    "    #    using rows in rda where Constraint Type is RDA or AI.\n",
    "    bmin = rda.loc[rda[\"Constraint Type\"].isin([\"RDA\", \"AI\"]), group]\n",
    "    bmax = rda.loc[rda[\"Constraint Type\"].isin([\"RDA\", \"AI\"]), group]\n",
    "\n",
    "    # Reindex so they have the same nutrients\n",
    "    bmin = bmin.reindex(bmax.index).dropna(how=\"all\")\n",
    "    bmax = bmax.reindex(bmin.index).dropna(how=\"all\")\n",
    "\n",
    "    # 2) Intersect df_vegan & prices to ensure matching foods\n",
    "    common_recipes = df_vegan.index.intersection(prices.index)\n",
    "    df_vegan = df_vegan.loc[common_recipes]\n",
    "    prices = prices.loc[common_recipes]\n",
    "\n",
    "    # 3) Build the \">= bmin\" constraints\n",
    "    nutrients = bmin.index.tolist()\n",
    "    for nut in nutrients:\n",
    "        if nut not in df_vegan.columns:\n",
    "            raise ValueError(f\"Nutrient '{nut}' not found in df_vegan columns.\")\n",
    "\n",
    "    # Each row in df_vegan is a food; columns are nutrients => shape: (n_foods, n_nutrients)\n",
    "    A_bmin = df_vegan[nutrients].to_numpy()\n",
    "\n",
    "    # Convert >= to <= by multiplying by -1\n",
    "    A_ub = -A_bmin.T  # shape: (n_nutrients, n_foods)\n",
    "    b_ub = -bmin.values  # shape: (n_nutrients,)\n",
    "\n",
    "    # 4) Build the cost vector\n",
    "    if \"price\" not in prices.columns:\n",
    "        raise ValueError(\"The 'prices' DataFrame must have a 'price' column.\")\n",
    "    cost_vector = prices[\"price\"].to_numpy()  # shape: (n_foods,)\n",
    "\n",
    "    # Each food's serving >= 0\n",
    "    bounds = [(0, None)] * len(df_vegan)\n",
    "\n",
    "    # 5) Solve the linear program\n",
    "    tol = 1e-6  # treat solution values smaller than this as zero\n",
    "    result = linprog(\n",
    "        c=cost_vector,\n",
    "        A_ub=A_ub,\n",
    "        b_ub=b_ub,\n",
    "        bounds=bounds,\n",
    "        method=\"highs\",\n",
    "        options={\"tol\": tol}\n",
    "    )\n",
    "\n",
    "    if not result.success:\n",
    "        raise RuntimeError(f\"Linear program failed: {result.message}\")\n",
    "\n",
    "    # 6) Print results in your screenshot style\n",
    "    print(f\"Cost of diet for a vegan {group} is ${result.fun:.2f} per day.\\n\")\n",
    "\n",
    "    # Build a Series for the solution\n",
    "    diet = pd.Series(result.x, index=prices.index, name=\"servings\")\n",
    "\n",
    "    # Print \"100s of grams/mL\" if 1 serving ~ 100 g/mL\n",
    "    diet_100 = (diet * 100).round(2)\n",
    "    print(f\"\\nAs a vegan {group}, you'll be eating (in 100s of grams or milliliters):\\n\")\n",
    "    print(diet_100[diet_100 > 0.01])\n",
    "\n",
    "    # Return the entire solver result for further inspection\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd7ca68-18a8-4880-892a-51163f4e7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = \"Female_endurance_athlete\"\n",
    "servings_series = min_cost_diet_with_remapped_names(\n",
    "    population=population,\n",
    "    rda=rda,\n",
    "    df_vegan=df_vegan,\n",
    "    prices=prices,\n",
    "    name_column=\"recipe\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c8e23-e54c-4139-bf6d-a27a629396e3",
   "metadata": {},
   "source": [
    "## Regional Differences in Minimum Cost Diet For Each Group ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b42bc-77d3-49d1-a8bf-0632622d07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Installations\n",
    "import pandas as pd\n",
    "import os\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2b355-c94e-45a2-ba86-6746437711f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/jovyan/Project2/CPI/food_affordability_CA.xls'\n",
    "affordability_CA = pd.read_excel(file_path)\n",
    "affordability_CA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca4f9d-8292-46e8-b7ab-697c57322079",
   "metadata": {},
   "source": [
    "## Regional CPI ##\n",
    "\n",
    "The followings are the census divisions: \n",
    "New England, Middle Atlantic, East North Central, West North Central, South Atlantic, East South Central, West South Central, Mountain, and  Pacific. Each dataframe has the CPI for each census region with the monthly CPI changes as well as annual and first half and second half. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72896a5-18bd-4517-bbc1-39848ce5aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the file path\n",
    "file_path_1 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_EastSouthCentral.csv'\n",
    "file_path_2 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_MiddleAtlantic.csv'\n",
    "file_path_3 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_East_North_Central.csv'\n",
    "file_path_4 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_Mountain.csv'\n",
    "file_path_5 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_NewEngland.csv'\n",
    "file_path_6 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_Pacific.csv'\n",
    "file_path_7 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_SouthAtlantic.csv'\n",
    "file_path_8 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_WestNorthCentral.csv'\n",
    "file_path_9 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_WestSouthCentral.csv'\n",
    "\n",
    "#individual files for each census regions\n",
    "CPI_East_South_Central = pd.read_csv(file_path_1)\n",
    "CPI_Middle_Atlantic = pd.read_csv(file_path_2)\n",
    "CPI_East_North_Central = pd.read_csv(file_path_3)\n",
    "CPI_Mountain = pd.read_csv(file_path_4)\n",
    "CPI_NewEngland = pd.read_csv(file_path_5)\n",
    "CPI_Pacific = pd.read_csv(file_path_6)\n",
    "CPI_South_Atlantic = pd.read_csv(file_path_7)\n",
    "CPI_West_North_Central = pd.read_csv(file_path_8)\n",
    "CPI_West_South_Central = pd.read_csv(file_path_9)\n",
    "\n",
    "#example of a dataframe\n",
    "CPI_East_South_Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1df2b-eee2-44f0-bb0f-d446e55c82e5",
   "metadata": {},
   "source": [
    "## Clean the Dataframe to make it easier to work with ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be19427-5a7b-498a-b29e-4cab9cebc348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of DataFrames\n",
    "cpi_dfs = {\n",
    "    \"CPI_East_South_Central\": CPI_East_South_Central,\n",
    "    \"CPI_Middle_Atlantic\": CPI_Middle_Atlantic,\n",
    "    \"CPI_East_North_Central\": CPI_East_North_Central,\n",
    "    \"CPI_Mountain\": CPI_Mountain,\n",
    "    \"CPI_NewEngland\": CPI_NewEngland,\n",
    "    \"CPI_Pacific\": CPI_Pacific,\n",
    "    \"CPI_South_Atlantic\": CPI_South_Atlantic,\n",
    "    \"CPI_West_North_Central\": CPI_West_North_Central,\n",
    "    \"CPI_West_South_Central\": CPI_West_South_Central\n",
    "}\n",
    "\n",
    "# Loop through all DataFrames and set \"Year\" as the index\n",
    "for name, df in cpi_dfs.items():\n",
    "    if \"Year\" in df.columns:  # Check if \"Year\" column exists\n",
    "        df.set_index(\"Year\", inplace=True)\n",
    "\n",
    "# Now all DataFrames have \"Year\" as the index\n",
    "\n",
    "CPI_East_North_Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b0e18-5ea1-4a9c-9332-68e0d7203572",
   "metadata": {},
   "source": [
    "2017 is the base year for CPI calculation for all the dataframe. We will use the formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d7958-c88c-4d85-b029-52790d2a7311",
   "metadata": {},
   "source": [
    "## Calculating Adjusted Cost of Minimum Diet Using CPI\n",
    "\n",
    "To determine the cost of a minimum diet for each region, we use the Consumer Price Index (CPI) as an adjustment factor. The formula is given by:\n",
    "\n",
    "$$\n",
    "\\text{Adjusted Cost}_{\\text{region}} = \\text{Base Cost} \\times \\frac{\\text{CPI}_{\\text{region}}}{\\text{CPI}_{\\text{base}}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **$\\text{Adjusted Cost}_{\\text{region}}$** is the estimated cost of the minimum diet in the specific region.\n",
    "- **$\\text{Base Cost}$** is the reference cost of the minimum diet (typically from a standard region or dataset).\n",
    "- **$\\text{CPI}_{\\text{region}}$** is the Consumer Price Index for the specific region.\n",
    "- **$\\text{CPI}_{\\text{base}}$** is the CPI of the reference region.\n",
    "\n",
    "This method adjusts the base cost according to regional price variations, ensuring that the diet cost reflects local economic conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393ee18-31e6-4b94-97a6-9f101893137f",
   "metadata": {},
   "source": [
    "## Change the variable name and structure AFTER sorting out the FINAL files ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc30b4e-3642-4e2b-991b-8cb8a10f421d",
   "metadata": {},
   "source": [
    "### Save the Minimum Cost Diet of Each Group as Variables ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bd9665bf-4d43-4a39-8d0d-938cc379540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_price_vegan_m_endurance_ath = 4.04\n",
    "min_price_vegan_f_endurance_ath = 3.97\n",
    "min_price_vegan_m_endurance_ath = 3.77\n",
    "min_price_vegan_f_non_ath = 3.28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb16e11-18fb-475e-b482-cbb51103d380",
   "metadata": {},
   "source": [
    "## The Calculated Adjusted Minimum Cost Diet as a Dataframe ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1216eff6-77d9-47a3-921c-9a82a199db0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Annual</th>\n",
       "      <th>HALF1</th>\n",
       "      <th>HALF2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>100.694</td>\n",
       "      <td>100.780</td>\n",
       "      <td>100.903</td>\n",
       "      <td>101.429</td>\n",
       "      <td>101.892</td>\n",
       "      <td>101.984</td>\n",
       "      <td>101.849</td>\n",
       "      <td>101.800</td>\n",
       "      <td>101.977</td>\n",
       "      <td>101.982</td>\n",
       "      <td>101.569</td>\n",
       "      <td>101.226</td>\n",
       "      <td>101.507</td>\n",
       "      <td>101.280</td>\n",
       "      <td>101.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>101.457</td>\n",
       "      <td>102.212</td>\n",
       "      <td>102.656</td>\n",
       "      <td>102.928</td>\n",
       "      <td>103.246</td>\n",
       "      <td>103.178</td>\n",
       "      <td>103.432</td>\n",
       "      <td>103.521</td>\n",
       "      <td>103.564</td>\n",
       "      <td>103.804</td>\n",
       "      <td>103.614</td>\n",
       "      <td>103.605</td>\n",
       "      <td>103.101</td>\n",
       "      <td>102.613</td>\n",
       "      <td>103.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>104.130</td>\n",
       "      <td>104.271</td>\n",
       "      <td>103.675</td>\n",
       "      <td>102.423</td>\n",
       "      <td>102.887</td>\n",
       "      <td>103.724</td>\n",
       "      <td>104.254</td>\n",
       "      <td>104.745</td>\n",
       "      <td>104.842</td>\n",
       "      <td>104.787</td>\n",
       "      <td>104.456</td>\n",
       "      <td>104.479</td>\n",
       "      <td>104.056</td>\n",
       "      <td>103.518</td>\n",
       "      <td>104.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>105.024</td>\n",
       "      <td>105.925</td>\n",
       "      <td>106.623</td>\n",
       "      <td>107.470</td>\n",
       "      <td>108.498</td>\n",
       "      <td>109.476</td>\n",
       "      <td>110.136</td>\n",
       "      <td>110.248</td>\n",
       "      <td>110.465</td>\n",
       "      <td>111.421</td>\n",
       "      <td>111.949</td>\n",
       "      <td>112.265</td>\n",
       "      <td>109.125</td>\n",
       "      <td>107.169</td>\n",
       "      <td>111.081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug  \\\n",
       "Year                                                                           \n",
       "2017      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018  100.694  100.780  100.903  101.429  101.892  101.984  101.849  101.800   \n",
       "2019  101.457  102.212  102.656  102.928  103.246  103.178  103.432  103.521   \n",
       "2020  104.130  104.271  103.675  102.423  102.887  103.724  104.254  104.745   \n",
       "2021  105.024  105.925  106.623  107.470  108.498  109.476  110.136  110.248   \n",
       "\n",
       "          Sep      Oct      Nov      Dec   Annual    HALF1    HALF2  \n",
       "Year                                                                 \n",
       "2017      NaN      NaN      NaN  100.000      NaN      NaN      NaN  \n",
       "2018  101.977  101.982  101.569  101.226  101.507  101.280  101.734  \n",
       "2019  103.564  103.804  103.614  103.605  103.101  102.613  103.590  \n",
       "2020  104.842  104.787  104.456  104.479  104.056  103.518  104.594  \n",
       "2021  110.465  111.421  111.949  112.265  109.125  107.169  111.081  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPI_East_North_Central.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "61cfbfd2-977b-4d68-a50d-ad88a2404614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Adjusted_Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>4.789106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>4.703904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>4.738965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>4.949859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.654744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>4.851802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>4.886486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>4.770370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>4.726034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Region  Adjusted_Cost\n",
       "0  East_South_Central       4.789106\n",
       "1     Middle_Atlantic       4.703904\n",
       "2  East_North_Central       4.738965\n",
       "3            Mountain       4.949859\n",
       "4          NewEngland       4.654744\n",
       "5             Pacific       4.851802\n",
       "6      South_Atlantic       4.886486\n",
       "7  West_North_Central       4.770370\n",
       "8  West_South_Central       4.726034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary containing all CPI DataFrames\n",
    "cpi_dfs = {\n",
    "    \"East_South_Central\": CPI_East_South_Central,\n",
    "    \"Middle_Atlantic\": CPI_Middle_Atlantic,\n",
    "    \"East_North_Central\": CPI_East_North_Central,\n",
    "    \"Mountain\": CPI_Mountain,\n",
    "    \"NewEngland\": CPI_NewEngland,\n",
    "    \"Pacific\": CPI_Pacific,\n",
    "    \"South_Atlantic\": CPI_South_Atlantic,\n",
    "    \"West_North_Central\": CPI_West_North_Central,\n",
    "    \"West_South_Central\": CPI_West_South_Central\n",
    "}\n",
    "\n",
    "# Define base year and minimum cost of diet\n",
    "base_year = 2017  #  CPI base year for all census region\n",
    "min_price_vegan_m_endurance_ath = min_price_vegan_m_endurance_ath \n",
    "\n",
    "# Create an empty list to store results\n",
    "adjusted_cost_data = []\n",
    "\n",
    "# Loop through each region's CPI data\n",
    "for region, df in cpi_dfs.items():\n",
    "    # Ensure Year is the index and fetch CPI values\n",
    "    if base_year in df.index and 2024 in df.index:\n",
    "        cpi_base = df.loc[base_year, \"Dec\"]  # CPI for base year is given in December\n",
    "        cpi_latest = df.loc[2024, \"Annual\"]  # CPI for latest available year which is 2024\n",
    "        # Calculate adjusted diet cost\n",
    "        adjusted_cost = min_price_vegan_m_endurance_ath * (cpi_latest / cpi_base)\n",
    "        \n",
    "        # Append results\n",
    "        adjusted_cost_data.append([region, adjusted_cost])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "adjusted_cost_df = pd.DataFrame(adjusted_cost_data, columns=[\"Region\", \"Adjusted_Cost\"])\n",
    "\n",
    "# Display the DataFrame in Jupyter Notebook\n",
    "display(adjusted_cost_df)  # For Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9a49e1cc-c2ef-4192-8efb-a877a15f4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_cost_by_cpi(min_price, cpi_dfs, base_year=2017, latest_year=2024):\n",
    "    \"\"\"\n",
    "    Adjusts a base diet cost using CPI data from multiple regions and returns\n",
    "    a DataFrame with the region name and adjusted costs.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    min_price : float\n",
    "        Minimum diet cost to be adjusted (e.g., min_price_vegan_m_endurance_ath)\n",
    "    cpi_dfs : dict of pd.DataFrame\n",
    "        Dictionary keyed by region. Each value is a DataFrame with CPI data for multiple years,\n",
    "        where the DataFrame index is years, and includes columns like 'Dec' and 'Annual'\n",
    "    base_year : int, default 2017\n",
    "        The year in the DataFrame(s) to use as a CPI base.\n",
    "    latest_year : int, default 2024\n",
    "        The year in the DataFrame(s) to use as the CPI for the latest adjustment.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with columns [\"Region\", \"Adjusted_Cost\"] where \"Region\" is the key\n",
    "        from the dictionary, and \"Adjusted_Cost\" is the adjusted cost for that region.\n",
    "    \"\"\"\n",
    "    adjusted_cost_data = []\n",
    "\n",
    "    for region, df in cpi_dfs.items():\n",
    "        # We check both the base and latest years are present in the index\n",
    "        if base_year in df.index and latest_year in df.index:\n",
    "            cpi_base = df.loc[base_year, \"Dec\"]\n",
    "            cpi_latest = df.loc[latest_year, \"Annual\"]\n",
    "            \n",
    "            # Calculate the adjusted cost\n",
    "            adjusted_cost = min_price * (cpi_latest / cpi_base)\n",
    "            \n",
    "            # Append to our list of results\n",
    "            adjusted_cost_data.append([region, adjusted_cost])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    adjusted_cost_df = pd.DataFrame(adjusted_cost_data, columns=[\"Region\", \"Adjusted_Cost\"])\n",
    "\n",
    "    return adjusted_cost_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "de8dc078-6937-47dd-92bf-67d2aeaa333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_price_vegan_m_endurance_ath = 4.04\n",
    "min_price_vegan_f_endurance_ath = 3.97\n",
    "min_price_vegan_m_non_ath = 3.77\n",
    "min_price_vegan_f_non_ath = 3.28\n",
    "\n",
    "diet_costs = {\n",
    "    \"vegan_m_endurance_ath\": min_price_vegan_m_endurance_ath,\n",
    "    \"vegan_f_endurance_ath\": min_price_vegan_f_endurance_ath,\n",
    "    \"vegan_m_non_ath\": min_price_vegan_m_non_ath,\n",
    "    \"vegan_f_non_ath\": min_price_vegan_f_non_ath,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "93cfaf8c-3747-4243-bb53-1d8332e3e120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Adjusted_Cost</th>\n",
       "      <th>Diet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>5.132093</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>5.040789</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>5.078361</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>5.304358</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.988107</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>5.199278</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>5.236446</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>5.112014</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>5.064504</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>5.043170</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>4.953448</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>4.990369</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>5.212451</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.901680</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>5.109192</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>5.145716</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>5.023440</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>4.976752</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>4.789106</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>4.703904</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>4.738965</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>4.949859</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.654744</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>4.851802</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>4.886486</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>4.770370</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>4.726034</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>4.166650</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>4.092522</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>4.123026</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>4.306509</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.049750</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>4.221196</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>4.251372</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>4.150348</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>4.111775</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Region  Adjusted_Cost              Diet_Type\n",
       "0   East_South_Central       5.132093  vegan_m_endurance_ath\n",
       "1      Middle_Atlantic       5.040789  vegan_m_endurance_ath\n",
       "2   East_North_Central       5.078361  vegan_m_endurance_ath\n",
       "3             Mountain       5.304358  vegan_m_endurance_ath\n",
       "4           NewEngland       4.988107  vegan_m_endurance_ath\n",
       "5              Pacific       5.199278  vegan_m_endurance_ath\n",
       "6       South_Atlantic       5.236446  vegan_m_endurance_ath\n",
       "7   West_North_Central       5.112014  vegan_m_endurance_ath\n",
       "8   West_South_Central       5.064504  vegan_m_endurance_ath\n",
       "9   East_South_Central       5.043170  vegan_f_endurance_ath\n",
       "10     Middle_Atlantic       4.953448  vegan_f_endurance_ath\n",
       "11  East_North_Central       4.990369  vegan_f_endurance_ath\n",
       "12            Mountain       5.212451  vegan_f_endurance_ath\n",
       "13          NewEngland       4.901680  vegan_f_endurance_ath\n",
       "14             Pacific       5.109192  vegan_f_endurance_ath\n",
       "15      South_Atlantic       5.145716  vegan_f_endurance_ath\n",
       "16  West_North_Central       5.023440  vegan_f_endurance_ath\n",
       "17  West_South_Central       4.976752  vegan_f_endurance_ath\n",
       "18  East_South_Central       4.789106        vegan_m_non_ath\n",
       "19     Middle_Atlantic       4.703904        vegan_m_non_ath\n",
       "20  East_North_Central       4.738965        vegan_m_non_ath\n",
       "21            Mountain       4.949859        vegan_m_non_ath\n",
       "22          NewEngland       4.654744        vegan_m_non_ath\n",
       "23             Pacific       4.851802        vegan_m_non_ath\n",
       "24      South_Atlantic       4.886486        vegan_m_non_ath\n",
       "25  West_North_Central       4.770370        vegan_m_non_ath\n",
       "26  West_South_Central       4.726034        vegan_m_non_ath\n",
       "27  East_South_Central       4.166650        vegan_f_non_ath\n",
       "28     Middle_Atlantic       4.092522        vegan_f_non_ath\n",
       "29  East_North_Central       4.123026        vegan_f_non_ath\n",
       "30            Mountain       4.306509        vegan_f_non_ath\n",
       "31          NewEngland       4.049750        vegan_f_non_ath\n",
       "32             Pacific       4.221196        vegan_f_non_ath\n",
       "33      South_Atlantic       4.251372        vegan_f_non_ath\n",
       "34  West_North_Central       4.150348        vegan_f_non_ath\n",
       "35  West_South_Central       4.111775        vegan_f_non_ath"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_adjusted_results = []\n",
    "\n",
    "for diet_name, min_price_val in diet_costs.items():\n",
    "    result_df = adjust_cost_by_cpi(min_price_val, cpi_dfs)\n",
    "    # Add a column to identify which diet cost this row corresponds to\n",
    "    result_df[\"Diet_Type\"] = diet_name\n",
    "    all_adjusted_results.append(result_df)\n",
    "\n",
    "# Concatenate all results into one DataFrame\n",
    "final_adjusted_costs_df = pd.concat(all_adjusted_results, ignore_index=True)\n",
    "\n",
    "final_adjusted_costs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fa30363c-3aef-471b-84c1-8e8455f6af01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Diet_Type</th>\n",
       "      <th>vegan_f_endurance_ath</th>\n",
       "      <th>vegan_f_non_ath</th>\n",
       "      <th>vegan_m_endurance_ath</th>\n",
       "      <th>vegan_m_non_ath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>East_North_Central</th>\n",
       "      <td>4.990369</td>\n",
       "      <td>4.123026</td>\n",
       "      <td>5.078361</td>\n",
       "      <td>4.738965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East_South_Central</th>\n",
       "      <td>5.043170</td>\n",
       "      <td>4.166650</td>\n",
       "      <td>5.132093</td>\n",
       "      <td>4.789106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middle_Atlantic</th>\n",
       "      <td>4.953448</td>\n",
       "      <td>4.092522</td>\n",
       "      <td>5.040789</td>\n",
       "      <td>4.703904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mountain</th>\n",
       "      <td>5.212451</td>\n",
       "      <td>4.306509</td>\n",
       "      <td>5.304358</td>\n",
       "      <td>4.949859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewEngland</th>\n",
       "      <td>4.901680</td>\n",
       "      <td>4.049750</td>\n",
       "      <td>4.988107</td>\n",
       "      <td>4.654744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pacific</th>\n",
       "      <td>5.109192</td>\n",
       "      <td>4.221196</td>\n",
       "      <td>5.199278</td>\n",
       "      <td>4.851802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South_Atlantic</th>\n",
       "      <td>5.145716</td>\n",
       "      <td>4.251372</td>\n",
       "      <td>5.236446</td>\n",
       "      <td>4.886486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West_North_Central</th>\n",
       "      <td>5.023440</td>\n",
       "      <td>4.150348</td>\n",
       "      <td>5.112014</td>\n",
       "      <td>4.770370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West_South_Central</th>\n",
       "      <td>4.976752</td>\n",
       "      <td>4.111775</td>\n",
       "      <td>5.064504</td>\n",
       "      <td>4.726034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Diet_Type           vegan_f_endurance_ath  vegan_f_non_ath  \\\n",
       "Region                                                       \n",
       "East_North_Central               4.990369         4.123026   \n",
       "East_South_Central               5.043170         4.166650   \n",
       "Middle_Atlantic                  4.953448         4.092522   \n",
       "Mountain                         5.212451         4.306509   \n",
       "NewEngland                       4.901680         4.049750   \n",
       "Pacific                          5.109192         4.221196   \n",
       "South_Atlantic                   5.145716         4.251372   \n",
       "West_North_Central               5.023440         4.150348   \n",
       "West_South_Central               4.976752         4.111775   \n",
       "\n",
       "Diet_Type           vegan_m_endurance_ath  vegan_m_non_ath  \n",
       "Region                                                      \n",
       "East_North_Central               5.078361         4.738965  \n",
       "East_South_Central               5.132093         4.789106  \n",
       "Middle_Atlantic                  5.040789         4.703904  \n",
       "Mountain                         5.304358         4.949859  \n",
       "NewEngland                       4.988107         4.654744  \n",
       "Pacific                          5.199278         4.851802  \n",
       "South_Atlantic                   5.236446         4.886486  \n",
       "West_North_Central               5.112014         4.770370  \n",
       "West_South_Central               5.064504         4.726034  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the table\n",
    "pivoted_df = final_adjusted_costs_df.pivot(\n",
    "    index=\"Region\", \n",
    "    columns=\"Diet_Type\", \n",
    "    values=\"Adjusted_Cost\"\n",
    ")\n",
    "\n",
    "# Optionally, you might want to sort the index or columns:\n",
    "pivoted_df = pivoted_df.sort_index().sort_index(axis=1)\n",
    "\n",
    "# Show the pivoted table\n",
    "pivoted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8942a52-1a49-4a75-9d3a-802a01910f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a850f9-874a-4cc8-a1f6-87172f968fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a857d-996b-4210-9693-f9798a0c37d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

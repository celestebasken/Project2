{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e1febe-907b-4e8b-9813-30c04a48e28d",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "45f46962",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install eep153_tools\n",
    "%pip install python_gnupg\n",
    "%pip install -U gspread_pandas\n",
    "#load in file from class\n",
    "def format_id(id,zeropadding=0):\n",
    "    \"\"\"Nice string format for any id, string or numeric.\n",
    "\n",
    "    Optional zeropadding parameter takes an integer\n",
    "    formats as {id:0z} where\n",
    "    \"\"\"\n",
    "    if pd.isnull(id) or id in ['','.']: return None\n",
    "\n",
    "    try:  # If numeric, return as string int\n",
    "        return ('%d' % id).zfill(zeropadding)\n",
    "    except TypeError:  # Not numeric\n",
    "        return id.split('.')[0].strip().zfill(zeropadding)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "data_url = \"https://docs.google.com/spreadsheets/d/1GTo423_gUJe1Von9jypWAbC0zSQ7WGegAWPuRi7eJAI/edit?gid=1410082681#gid=1410082681\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7f10138f-ba5d-4e3c-ac9b-3220baf9f07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_foodcode</th>\n",
       "      <th>recipe</th>\n",
       "      <th>ingred_code</th>\n",
       "      <th>ingred_desc</th>\n",
       "      <th>ingred_wt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11340000</td>\n",
       "      <td>Imitation milk, non-soy, sweetened</td>\n",
       "      <td>43543</td>\n",
       "      <td>Milk, imitation, non-soy</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11460150</td>\n",
       "      <td>Yogurt, frozen, NS as to flavor, lowfat milk</td>\n",
       "      <td>1298</td>\n",
       "      <td>Yogurt, frozen, flavors other than chocolate, ...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>1117</td>\n",
       "      <td>Yogurt, plain, low fat, 12 grams protein per 8...</td>\n",
       "      <td>81.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>19166</td>\n",
       "      <td>Cocoa, dry powder, unsweetened, processed with...</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11460160</td>\n",
       "      <td>Yogurt, frozen, chocolate, lowfat milk</td>\n",
       "      <td>19335</td>\n",
       "      <td>Sugars, granulated</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_foodcode                                        recipe ingred_code  \\\n",
       "0        11340000            Imitation milk, non-soy, sweetened       43543   \n",
       "1        11460150  Yogurt, frozen, NS as to flavor, lowfat milk        1298   \n",
       "2        11460160        Yogurt, frozen, chocolate, lowfat milk        1117   \n",
       "3        11460160        Yogurt, frozen, chocolate, lowfat milk       19166   \n",
       "4        11460160        Yogurt, frozen, chocolate, lowfat milk       19335   \n",
       "\n",
       "                                         ingred_desc  ingred_wt  \n",
       "0                           Milk, imitation, non-soy      100.0  \n",
       "1  Yogurt, frozen, flavors other than chocolate, ...      100.0  \n",
       "2  Yogurt, plain, low fat, 12 grams protein per 8...       81.8  \n",
       "3  Cocoa, dry powder, unsweetened, processed with...        5.2  \n",
       "4                                 Sugars, granulated       13.0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from eep153_tools.sheets import read_sheets\n",
    "\n",
    "#create recipes df\n",
    "recipes = read_sheets(data_url, sheet=\"recipes\")\n",
    "recipes = (recipes\n",
    "           .assign(parent_foodcode = lambda df: df[\"parent_foodcode\"].apply(format_id),\n",
    "                   ingred_code = lambda df: df[\"ingred_code\"].apply(format_id))\n",
    "           .rename(columns={\"parent_desc\": \"recipe\"}))\n",
    "recipes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbd476-3de0-4616-a723-67c858ed48e9",
   "metadata": {},
   "source": [
    "## [A] Dietary Reference Intakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c0ea5-6751-4686-89ee-e90538bdc6f2",
   "metadata": {},
   "source": [
    "### Create RDA df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7cf2be9c-7993-4c29-9666-d42dc0bfa46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads dietary reference intake (RDA/AI) data from a Google Sheet, formats it, and extracts the  minimum required intake values for various nutrients.\n",
    "\n",
    "\n",
    "# Read the \"rda\" sheet from the Google Sheet data_url\n",
    "rda = read_sheets(data_url, sheet=\"rda_2\")\n",
    "\n",
    "# Set \"Nutrient\" as the index for easier access to nutrient-based data\n",
    "rda = rda.set_index(\"Nutrient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "18e89875-966f-41db-bf44-3bef0a3d3b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dietary_reference_intake(age, sex, data, athlete = bool):\n",
    "    \"\"\"\n",
    "    Returns a pandas Series of dietary reference intakes (RDA/AI) for a person\n",
    "    given their age, sex, and whether they are an endurance athlete.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Validate inputs\n",
    "    if age < 1:\n",
    "        raise ValueError(\"Age must be a positive integer.\")\n",
    "    sex = sex.lower()\n",
    "    if sex not in [\"male\", \"female\", \"child\"]:\n",
    "        raise ValueError(\"Sex must be 'male', 'female', or 'child'.\")\n",
    "\n",
    "    # 2) Determine the correct column name\n",
    "    col = _determine_rda_column(age, sex, athlete)\n",
    "\n",
    "    # 3) Filter the DataFrame to only RDA or AI constraints\n",
    "    rda_data = data[data[\"Constraint Type\"].isin([\"RDA\", \"AI\"])].copy()\n",
    "\n",
    "    # 4) Ensure the chosen column exists\n",
    "    if col not in rda_data.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in RDA DataFrame.\")\n",
    "\n",
    "    # 5) Return the RDA/AI Series (dropping any NaNs)\n",
    "    return rda_data[col].dropna()\n",
    "\n",
    "\n",
    "def _determine_rda_column(age, sex, athlete):\n",
    "    \"\"\"\n",
    "    Internal helper that maps (age, sex, athlete) to the correct RDA column name.\n",
    "    \"\"\"\n",
    "\n",
    "    # If user explicitly says 'child' and age <= 3\n",
    "    if sex == \"child\" and age <= 3:\n",
    "        return \"Child_1_3\"\n",
    "    elif sex == \"child\" and age > 3:\n",
    "        # Decide how you want to handle older children if 'child' was given\n",
    "        raise ValueError(\"Child category only defined up to age 3. Use 'male' or 'female' for older children.\")\n",
    "\n",
    "    # For male or female:\n",
    "    if sex == \"male\":\n",
    "        # If 19 <= age <= 30 and athlete=True => \"Male_endurance_athlete\"\n",
    "        if 19 <= age <= 30 and athlete:\n",
    "            return \"Male_endurance_athlete\"\n",
    "        # Otherwise pick by age range\n",
    "        if 1 <= age <= 3:\n",
    "            return \"Child_1_3\"\n",
    "        elif 4 <= age <= 8:\n",
    "            return \"Male_4_8\"\n",
    "        elif 9 <= age <= 13:\n",
    "            return \"Male_9_13\"\n",
    "        elif 14 <= age <= 18:\n",
    "            return \"Male_14_18\"\n",
    "        elif 19 <= age <= 30:\n",
    "            return \"Male_19_30\"\n",
    "        elif 31 <= age <= 50:\n",
    "            return \"Male_31_50\"\n",
    "        else:  # age >= 51\n",
    "            return \"Male_51U\"\n",
    "\n",
    "    elif sex == \"female\":\n",
    "        # If 19 <= age <= 30 and athlete=True => \"Female_endurance_athlete\"\n",
    "        if 19 <= age <= 30 and athlete:\n",
    "            return \"Female_endurance_athlete\"\n",
    "        # Otherwise pick by age range\n",
    "        if 1 <= age <= 3:\n",
    "            return \"Child_1_3\"\n",
    "        elif 4 <= age <= 8:\n",
    "            return \"Female_4_8\"\n",
    "        elif 9 <= age <= 13:\n",
    "            return \"Female_9_13\"\n",
    "        elif 14 <= age <= 18:\n",
    "            return \"Female_14_18\"\n",
    "        elif 19 <= age <= 30:\n",
    "            return \"Female_19_30\"\n",
    "        elif 31 <= age <= 50:\n",
    "            return \"Female_31_50\"\n",
    "        else:  # age >= 51\n",
    "            return \"Female_51U\"\n",
    "\n",
    "    # If none of the above matched\n",
    "    raise ValueError(\"Could not determine an RDA column for the given inputs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "aff101e7-9a55-4d20-8182-1302c5cfb187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nutrient\n",
       "Energy            3500.0\n",
       "Protein            112.0\n",
       "Carbohydrate       560.0\n",
       "Dietary Fiber       38.0\n",
       "Linoleic Acid       17.0\n",
       "Linolenic Acid       1.6\n",
       "Calcium           1000.0\n",
       "Iron                 8.0\n",
       "Magnesium          400.0\n",
       "Phosphorus         700.0\n",
       "Potassium         4700.0\n",
       "Zinc                11.0\n",
       "Copper               0.9\n",
       "Selenium            55.0\n",
       "Vitamin A          900.0\n",
       "Vitamin E           15.0\n",
       "Vitamin D           15.0\n",
       "Vitamin C           90.0\n",
       "Thiamin              1.3\n",
       "Riboflavin           1.9\n",
       "Niacin              29.0\n",
       "Vitamin B6           1.3\n",
       "Vitamin B12          2.4\n",
       "Choline            550.0\n",
       "Vitamin K          120.0\n",
       "Folate             400.0\n",
       "Name: Male_endurance_athlete, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example call for a 25-year-old male endurance athlete\n",
    "dietary_reference_intake(age=25, sex=\"male\", data=rda, athlete=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0230100-922b-4b09-99b9-d2cb3330c281",
   "metadata": {},
   "source": [
    "# Function that filters our data to contain only foods we want in our VEGAN df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e7a7e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of non-vegan keywords AND non-natural foods keywords (including frozen, processed, etc).\n",
    "NON_VEGAN_KEYWORDS = [\n",
    "    \"beef\", \"pork\", \"chicken\", \"turkey\", \"fish\", \"seafood\", \"shellfish\", \"shrimp\", \"crab\",\"crabs\",\n",
    "    \"lamb\", \"goat\", \"duck\", \"goose\", \"tuna\", \"salmon\", \"cod\", \"bacon\", \"ham\",\n",
    "    \"shellfish\", \"lobster\", \"mussels\", \"oysters\", \"scallops\", \"octopus\", \"eel\",\n",
    "    \"organ meat\", \"milk\",\"Eggnog\" \"cheese\", \"butter\", \"cream\",\"ice cream\", \"yogurt\", \"whey\",\n",
    "    \"casein\", \"lactose\", \"ghee\", \"buttermilk\", \"egg\", \"eggs\", \"mayo\", \"mayonnaise\", \"albumen\",\n",
    "    \"albumin\", \"lysozyme\", \"ovomucoid\", \"ovomucin\", \"ovovitellin\", \"honey\",\n",
    "    \"bee pollen\", \"royal jelly\", \"propolis\", \"shellac\", \"confectioner’s glaze\",\n",
    "    \"carmine\", \"cochineal\", \"lard\", \"tallow\", \"suet\", \"gelatin\", \"collagen\",\n",
    "    \"isinglass\", \"bone broth\", \"bone stock\", \"fish sauce\", \"oyster sauce\",\n",
    "    \"shrimp paste\", \"worcestershire sauce\", \"anchovies\", \"rennet\", \"pepsin\",\n",
    "    \"bone char\", \"vitamin d3\", \"lanolin\", \"omega-3 fish oil\", \"caseinate\",\n",
    "    \"lecithin (egg)\", \"cysteine\", \"l-cysteine\", \"glycerin (animal)\",\n",
    "    \"glycerol (animal)\", \"stearic acid (animal)\", \"tallowate\", \"sodium tallowate\",\n",
    "    \"capric acid\", \"caprylic acid\", \"cheese\", \"pudding\", \"processed\", \"veal\",'sirloin', \"steak\", \"animal\",\n",
    "    \"Custard\", \"Mousse\", \"chocolate\", \"Meatballs\", \"meat\", \"Gravy\", \"poultry\",\"baby\", \"frozen\", 'dairy', 'lump',\"peas\",\"school\", \"mix\"\n",
    "]\n",
    "\n",
    "#this partal match: \"milkshake\" or \"eggroll\" will get flagged (since \"milk\" or \"egg\" is in the keyword list).\n",
    "NON_VEGAN_PATTERN = re.compile(\n",
    "    '|'.join(map(re.escape, NON_VEGAN_KEYWORDS)),\n",
    "    re.IGNORECASE\n",
    ")\n",
    "#Filters out all the foods vegans can't consume from a df and returns a filtered df\n",
    "\n",
    "def filter_vegan_ingredients(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 1) Convert to string, lowercase, remove punctuation\n",
    "    df[\"recipe\"] = df[\"recipe\"].astype(str).str.lower().fillna(\"\")\n",
    "    df[\"recipe\"] = df[\"recipe\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "    df[\"ingred_desc\"] = df[\"ingred_desc\"].astype(str).str.lower().fillna(\"\")\n",
    "    df[\"ingred_desc\"] = df[\"ingred_desc\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "    # 2) Create a mask for rows that do NOT contain non-vegan keywords\n",
    "    mask = ~(df[\"recipe\"].str.contains(NON_VEGAN_PATTERN, na=False, regex=True) |\n",
    "             df[\"ingred_desc\"].str.contains(NON_VEGAN_PATTERN, na=False, regex=True))\n",
    "\n",
    "    return df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "230ff7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10823, 5)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vegan_recipes = filter_vegan_ingredients(recipes)\n",
    "vegan_recipes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0dfc57-bdf5-4989-b5b0-83334a7317e1",
   "metadata": {},
   "source": [
    "# [A] Nutritional content of different foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "da91b8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingred_code</th>\n",
       "      <th>Ingredient description</th>\n",
       "      <th>Capric acid</th>\n",
       "      <th>Lauric acid</th>\n",
       "      <th>Myristic acid</th>\n",
       "      <th>Palmitic acid</th>\n",
       "      <th>Palmitoleic acid</th>\n",
       "      <th>Stearic acid</th>\n",
       "      <th>Oleic acid</th>\n",
       "      <th>Linoleic Acid</th>\n",
       "      <th>...</th>\n",
       "      <th>Vitamin B12</th>\n",
       "      <th>Vitamin B-12, added</th>\n",
       "      <th>Vitamin B6</th>\n",
       "      <th>Vitamin C</th>\n",
       "      <th>Vitamin D</th>\n",
       "      <th>Vitamin E</th>\n",
       "      <th>Vitamin E, added</th>\n",
       "      <th>Vitamin K</th>\n",
       "      <th>Water</th>\n",
       "      <th>Zinc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>2.529</td>\n",
       "      <td>2.587</td>\n",
       "      <td>7.436</td>\n",
       "      <td>21.697</td>\n",
       "      <td>0.961</td>\n",
       "      <td>9.999</td>\n",
       "      <td>19.961</td>\n",
       "      <td>2.728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.87</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>2.039</td>\n",
       "      <td>2.354</td>\n",
       "      <td>7.515</td>\n",
       "      <td>20.531</td>\n",
       "      <td>1.417</td>\n",
       "      <td>7.649</td>\n",
       "      <td>17.370</td>\n",
       "      <td>2.713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.793</td>\n",
       "      <td>10.005</td>\n",
       "      <td>26.166</td>\n",
       "      <td>2.228</td>\n",
       "      <td>12.056</td>\n",
       "      <td>25.026</td>\n",
       "      <td>2.247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.491</td>\n",
       "      <td>3.301</td>\n",
       "      <td>9.153</td>\n",
       "      <td>0.816</td>\n",
       "      <td>3.235</td>\n",
       "      <td>6.622</td>\n",
       "      <td>0.536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>42.41</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.482</td>\n",
       "      <td>3.227</td>\n",
       "      <td>8.655</td>\n",
       "      <td>0.817</td>\n",
       "      <td>3.455</td>\n",
       "      <td>7.401</td>\n",
       "      <td>0.491</td>\n",
       "      <td>...</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>41.11</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ingred_code      Ingredient description  Capric acid  Lauric acid  \\\n",
       "0        1001              Butter, salted        2.529        2.587   \n",
       "1        1002  Butter, whipped, with salt        2.039        2.354   \n",
       "2        1003       Butter oil, anhydrous        2.495        2.793   \n",
       "3        1004                Cheese, blue        0.601        0.491   \n",
       "4        1005               Cheese, brick        0.585        0.482   \n",
       "\n",
       "   Myristic acid  Palmitic acid  Palmitoleic acid  Stearic acid  Oleic acid  \\\n",
       "0          7.436         21.697             0.961         9.999      19.961   \n",
       "1          7.515         20.531             1.417         7.649      17.370   \n",
       "2         10.005         26.166             2.228        12.056      25.026   \n",
       "3          3.301          9.153             0.816         3.235       6.622   \n",
       "4          3.227          8.655             0.817         3.455       7.401   \n",
       "\n",
       "   Linoleic Acid  ...  Vitamin B12  Vitamin B-12, added  Vitamin B6  \\\n",
       "0          2.728  ...         0.17                  0.0       0.003   \n",
       "1          2.713  ...         0.07                  0.0       0.008   \n",
       "2          2.247  ...         0.01                  0.0       0.001   \n",
       "3          0.536  ...         1.22                  0.0       0.166   \n",
       "4          0.491  ...         1.26                  0.0       0.065   \n",
       "\n",
       "   Vitamin C  Vitamin D  Vitamin E  Vitamin E, added  Vitamin K  Water  Zinc  \n",
       "0        0.0        0.0       2.32               0.0        7.0  15.87  0.09  \n",
       "1        0.0        0.0       1.37               0.0        4.6  16.72  0.05  \n",
       "2        0.0        0.0       2.80               0.0        8.6   0.24  0.01  \n",
       "3        0.0        0.5       0.25               0.0        2.4  42.41  2.66  \n",
       "4        0.0        0.5       0.26               0.0        2.5  41.11  2.60  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe_id\n",
      "11115400    kefir ns as to fat content\n",
      "11440060                  tzatziki dip\n",
      "11551050             licuado or batido\n",
      "11553100            fruit smoothie nfs\n",
      "11710000            infant formula nfs\n",
      "Name: recipe, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_264/1412862123.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vegan_recipes['ingred_wt'] = vegan_recipes['ingred_wt']/vegan_recipes.groupby(['parent_foodcode'])['ingred_wt'].transform(\"sum\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Capric acid</th>\n",
       "      <th>Lauric acid</th>\n",
       "      <th>Myristic acid</th>\n",
       "      <th>Palmitic acid</th>\n",
       "      <th>Palmitoleic acid</th>\n",
       "      <th>Stearic acid</th>\n",
       "      <th>Oleic acid</th>\n",
       "      <th>Linoleic Acid</th>\n",
       "      <th>Linolenic Acid</th>\n",
       "      <th>Stearidonic acid</th>\n",
       "      <th>...</th>\n",
       "      <th>Vitamin B-12, added</th>\n",
       "      <th>Vitamin B6</th>\n",
       "      <th>Vitamin C</th>\n",
       "      <th>Vitamin D</th>\n",
       "      <th>Vitamin E</th>\n",
       "      <th>Vitamin E, added</th>\n",
       "      <th>Vitamin K</th>\n",
       "      <th>Water</th>\n",
       "      <th>Zinc</th>\n",
       "      <th>recipe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11115400</th>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>87.445000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>kefir ns as to fat content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11440060</th>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>5.760400</td>\n",
       "      <td>0.638909</td>\n",
       "      <td>0.995345</td>\n",
       "      <td>36.284691</td>\n",
       "      <td>4.998000</td>\n",
       "      <td>0.392055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.147273</td>\n",
       "      <td>13.958182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.355091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.832727</td>\n",
       "      <td>31.587818</td>\n",
       "      <td>0.151091</td>\n",
       "      <td>tzatziki dip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11551050</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.053557</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.026779</td>\n",
       "      <td>0.056836</td>\n",
       "      <td>0.038064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.194179</td>\n",
       "      <td>26.891409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.089829</td>\n",
       "      <td>71.071385</td>\n",
       "      <td>0.127375</td>\n",
       "      <td>licuado or batido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11553100</th>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.083665</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.019192</td>\n",
       "      <td>0.037394</td>\n",
       "      <td>0.021949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.302079</td>\n",
       "      <td>8.717063</td>\n",
       "      <td>1.868939</td>\n",
       "      <td>0.103719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406460</td>\n",
       "      <td>66.590436</td>\n",
       "      <td>0.133152</td>\n",
       "      <td>fruit smoothie nfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11710000</th>\n",
       "      <td>0.058277</td>\n",
       "      <td>0.396867</td>\n",
       "      <td>0.162658</td>\n",
       "      <td>0.503481</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.128840</td>\n",
       "      <td>1.285942</td>\n",
       "      <td>0.657051</td>\n",
       "      <td>0.067309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18255</td>\n",
       "      <td>0.039897</td>\n",
       "      <td>6.983419</td>\n",
       "      <td>0.981209</td>\n",
       "      <td>0.778814</td>\n",
       "      <td>0.778814</td>\n",
       "      <td>5.620118</td>\n",
       "      <td>87.460612</td>\n",
       "      <td>0.586249</td>\n",
       "      <td>infant formula nfs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Capric acid  Lauric acid  Myristic acid  Palmitic acid  \\\n",
       "recipe_id                                                           \n",
       "11115400      0.019500     0.026000       0.094500       0.280500   \n",
       "11440060      0.005673     0.000273       0.000545       5.760400   \n",
       "11551050      0.000480     0.000959       0.000959       0.053557   \n",
       "11553100      0.000813     0.001626       0.001626       0.083665   \n",
       "11710000      0.058277     0.396867       0.162658       0.503481   \n",
       "\n",
       "           Palmitoleic acid  Stearic acid  Oleic acid  Linoleic Acid  \\\n",
       "recipe_id                                                              \n",
       "11115400           0.018500      0.106500    0.252000       0.037500   \n",
       "11440060           0.638909      0.995345   36.284691       4.998000   \n",
       "11551050           0.005183      0.003557    0.026779       0.056836   \n",
       "11553100           0.008129      0.004065    0.019192       0.037394   \n",
       "11710000           0.005924      0.128840    1.285942       0.657051   \n",
       "\n",
       "           Linolenic Acid  Stearidonic acid  ...  Vitamin B-12, added  \\\n",
       "recipe_id                                    ...                        \n",
       "11115400         0.005500               0.0  ...              0.00000   \n",
       "11440060         0.392055               0.0  ...              0.00000   \n",
       "11551050         0.038064               0.0  ...              0.00000   \n",
       "11553100         0.021949               0.0  ...              0.00000   \n",
       "11710000         0.067309               0.0  ...              0.18255   \n",
       "\n",
       "           Vitamin B6  Vitamin C  Vitamin D  Vitamin E  Vitamin E, added  \\\n",
       "recipe_id                                                                  \n",
       "11115400     0.059000   0.850000   1.050000   0.040000          0.000000   \n",
       "11440060     0.147273  13.958182   0.000000   7.355091          0.000000   \n",
       "11551050     0.194179  26.891409   0.000000   0.160010          0.000000   \n",
       "11553100     0.302079   8.717063   1.868939   0.103719          0.000000   \n",
       "11710000     0.039897   6.983419   0.981209   0.778814          0.778814   \n",
       "\n",
       "           Vitamin K      Water      Zinc                      recipe  \n",
       "recipe_id                                                              \n",
       "11115400    0.650000  87.445000  0.450000  kefir ns as to fat content  \n",
       "11440060   30.832727  31.587818  0.151091                tzatziki dip  \n",
       "11551050    1.089829  71.071385  0.127375           licuado or batido  \n",
       "11553100    0.406460  66.590436  0.133152          fruit smoothie nfs  \n",
       "11710000    5.620118  87.460612  0.586249          infant formula nfs  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create nutrition df\n",
    "nutrition = (read_sheets(data_url, sheet=\"nutrients\")\n",
    "             .assign(ingred_code = lambda df: df[\"ingred_code\"].apply(format_id)))\n",
    "\n",
    "display(nutrition.head())\n",
    "\n",
    "# normalize weights to percentage terms. \n",
    "vegan_recipes['ingred_wt'] = vegan_recipes['ingred_wt']/vegan_recipes.groupby(['parent_foodcode'])['ingred_wt'].transform(\"sum\")\n",
    "\n",
    "# we're going to extend the recipes data frame to include the nutrient profiles of its ingredients (in 100g)\n",
    "df_vegan = vegan_recipes.merge(nutrition, how=\"left\", on=\"ingred_code\")\n",
    "\n",
    "# multiply all nutrients per 100g of an ingredient by the weight of that ingredient in a recipe.\n",
    "numeric_cols = list(df_vegan.select_dtypes(include=[\"number\"]).columns)\n",
    "numeric_cols.remove(\"ingred_wt\")\n",
    "df_vegan[numeric_cols] = df_vegan[numeric_cols].mul(df_vegan[\"ingred_wt\"], axis=0)\n",
    "\n",
    "# sum nutrients of food codes (over the multiple ingredients)\n",
    "# python tip: one can merge dictionaries dict1 dict2 using **, that is: dict_merge = {**dict1, **dict2}. The ** effectively \"unpacks\" the key value pairs in each dictionary\n",
    "df_vegan = df_vegan.groupby('parent_foodcode').agg({**{col: \"sum\" for col in numeric_cols},\n",
    "                                        \"recipe\": \"first\"})\n",
    "\n",
    "df_vegan.index.name = \"recipe_id\"\n",
    "\n",
    "food_names = df_vegan[\"recipe\"]\n",
    "print(food_names.head())\n",
    "df_vegan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623febe-fcf5-42cf-bede-1f48a8f4032e",
   "metadata": {},
   "source": [
    "# [A] Data on prices for different foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ad86658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2011/2012', '2013/2014', '2015/2016', '2017/2018'], dtype='object', name='year')\n",
      "We have prices for 4435 unique recipes (FNDDS food codes)\n",
      "Index(['2011/2012', '2013/2014', '2015/2016', '2017/2018'], dtype='object', name='year')\n",
      "We have prices for 4435 unique recipes (FNDDS food codes)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This reads food price data from a Google Sheet, formats it, and extracts the latest available price data for food items identified by their \"food_code\". \n",
    "#It then removes missing price values and provides a count of the number of unique food codes with prices.\n",
    "\n",
    "\n",
    "# Read the \"prices\" sheet from the Google Sheet data_url\n",
    "# Keeping only the relevant columns: \"food_code\", \"year\", and \"price\"\n",
    "prices = read_sheets(data_url, sheet=\"prices\")[[\"food_code\", \"year\", \"price\"]]\n",
    "\n",
    "# Format the \"food_code\" column using a function `format_id`\n",
    "# (Assumption: `format_id` is defined elsewhere to standardize the format)\n",
    "prices[\"food_code\"] = prices[\"food_code\"].apply(format_id)\n",
    "\n",
    "# Set a MultiIndex with levels: \"year\" and \"food_code\"\n",
    "prices = prices.set_index([\"year\", \"food_code\"])\n",
    "\n",
    "# Print available years in the dataset (first level of MultiIndex)\n",
    "print(prices.index.levels[0])\n",
    "\n",
    "# Extract price data for the most recent year (assumed to be \"2017/2018\")\n",
    "prices = prices.xs(\"2017/2018\", level=\"year\")\n",
    "\n",
    "# Drop rows where the price is missing (\"NA\" values in the \"price\" column)\n",
    "prices = prices.dropna(subset=[\"price\"])\n",
    "\n",
    "# Print the number of unique recipes (food codes) with valid price data\n",
    "print(f\"We have prices for {prices.shape[0]} unique recipes (FNDDS food codes)\")\n",
    "\n",
    "\n",
    "prices = read_sheets(data_url, sheet=\"prices\")[[\"food_code\", \"year\", \"price\"]]\n",
    "\n",
    "prices[\"food_code\"] = prices[\"food_code\"].apply(format_id)\n",
    "\n",
    "prices = prices.set_index([\"year\", \"food_code\"])\n",
    "print(prices.index.levels[0])\n",
    "\n",
    "# we'll focus on the latest price data\n",
    "prices = prices.xs(\"2017/2018\", level=\"year\")\n",
    "\n",
    "# drop rows of prices where the price is \"NA\"\n",
    "prices = prices.dropna(subset=\"price\")\n",
    "\n",
    "print(f\"We have prices for {prices.shape[0]} unique recipes (FNDDS food codes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "678aeefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script ensures that the vegan food dataset (df_vegan) and the prices dataset contain only matching food items.\n",
    "# It then maps food codes to their actual names and transposes the nutrient data for further analysis.\n",
    "\n",
    "# Find the common food items between df_vegan and prices datasets\n",
    "common_recipes = df_vegan.index.intersection(prices.index)\n",
    "\n",
    "# Subset both data frames to include only common food items\n",
    "df_vegan = df_vegan.loc[common_recipes]\n",
    "prices = prices.loc[common_recipes]\n",
    "\n",
    "\n",
    "# Remap the index of the prices DataFrame to use actual food names instead of food codes by applying the \"food_names\" mapping.\n",
    "prices.index = prices.index.map(food_names)\n",
    "\n",
    "# Transpose df_vegan so that nutrients become rows and food items become columns\n",
    "A_all = df_vegan.T\n",
    "\n",
    "#print(prices.head())  \n",
    "#print(A_all.head())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1a724-3896-4c38-b863-04a69a653fb4",
   "metadata": {},
   "source": [
    "## [A] Solution - a function that optimizes for each group in our population of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "71773f34-3b81-4f62-bbf2-4b33485322e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog as lp\n",
    "\n",
    "def calculate_vegan_diet_cost(group):\n",
    "    \"\"\"\n",
    "    Demographic group. Must be one of:\n",
    "                     ['Female_19_30', 'Female_endurance_athlete', \n",
    "                      'Male_19_30', 'Male_endurance_athlete']\n",
    "    \"\"\"\n",
    "    valid_groups = ['Female_19_30', 'Female_endurance_athlete', \n",
    "                    'Male_19_30', 'Male_endurance_athlete']\n",
    "    if group not in valid_groups:\n",
    "        raise ValueError(f\"Invalid demographic group selected. Must be one of: {valid_groups}\")\n",
    "\n",
    "    # Create lower and upper bounds from the RDA DataFrame\n",
    "    bmin = rda.loc[rda['Constraint Type'].isin(['RDA', 'AI']), group]\n",
    "    bmax = rda.loc[rda['Constraint Type'].isin(['UL']), group]\n",
    "\n",
    "    # Keep only the nutrients present in bmin and bmax using the nutrient matrix A_all\n",
    "    Amin = A_all.reindex(bmin.index).dropna(how='all')\n",
    "    Amax = A_all.reindex(bmax.index).dropna(how='all')\n",
    "\n",
    "    # Combine lower and upper bounds; for upper bounds, multiply by -1\n",
    "    b = pd.concat([bmin, -bmax])\n",
    "    A = pd.concat([Amin, -Amax])\n",
    "\n",
    "    # Solve the linear programming problem using a tolerance for small numbers\n",
    "    tol = 1e-6\n",
    "    result = lp(prices, -A, -b, method='highs')\n",
    "\n",
    "    # Extract the solution: servings for each food\n",
    "    diet = pd.Series(result.x, index=prices.index)\n",
    "    min_price = result.fun\n",
    "    selected_foods = round(diet[diet >= tol], 2)\n",
    "\n",
    "    # Print results only once:\n",
    "    print(f\"Cost of diet for a vegan {group} is ${min_price:.2f} per day.\\n\")\n",
    "    print(f\"As a vegan {group} you'll be eating (in 100s of grams or milliliters): \\n\")\n",
    "    diet_df = pd.DataFrame({\"Food\": selected_foods.index, \"Quantity\": selected_foods.values})\n",
    "    print(diet_df.to_string(index=False))\n",
    "    \n",
    "    return min_price, selected_foods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dda0b0b0-5ab7-4bc6-a248-c2debafe2a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of diet for a vegan Female_19_30 is $3.36 per day.\n",
      "\n",
      "As a vegan Female_19_30 you'll be eating (in 100s of grams or milliliters): \n",
      "\n",
      "                                         Food  Quantity\n",
      "                    peruvian beans from dried      0.47\n",
      "                vermicelli made from soybeans      1.56\n",
      "                            peanuts unroasted      0.07\n",
      "cereal kelloggs allbran complete wheat flakes      0.01\n",
      "                           cereal rice flakes      0.37\n",
      "                           cereal toasted oat      1.63\n",
      "                 beans and rice with tomatoes     10.15\n",
      "                                 cilantro raw      0.11\n",
      "               margarineoil blend stick light      0.14\n"
     ]
    }
   ],
   "source": [
    "calculate_vegan_diet_cost('Female_19_30');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11077bc-f42c-45b7-8f0c-88fb9951a8e2",
   "metadata": {},
   "source": [
    "### For Loop That Runs Through All The Demographic Groups ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8b202a6f-b8ba-41e3-b7b5-502bd7cf7fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m### Running diet optimization for Female_19_30 ###\u001b[0m\n",
      "\n",
      "Cost of diet for a vegan Female_19_30 is $3.36 per day.\n",
      "\n",
      "As a vegan Female_19_30 you'll be eating (in 100s of grams or milliliters): \n",
      "\n",
      "                                         Food  Quantity\n",
      "                    peruvian beans from dried      0.47\n",
      "                vermicelli made from soybeans      1.56\n",
      "                            peanuts unroasted      0.07\n",
      "cereal kelloggs allbran complete wheat flakes      0.01\n",
      "                           cereal rice flakes      0.37\n",
      "                           cereal toasted oat      1.63\n",
      "                 beans and rice with tomatoes     10.15\n",
      "                                 cilantro raw      0.11\n",
      "               margarineoil blend stick light      0.14\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "\u001b[1m### Running diet optimization for Female_endurance_athlete ###\u001b[0m\n",
      "\n",
      "Cost of diet for a vegan Female_endurance_athlete is $3.98 per day.\n",
      "\n",
      "As a vegan Female_endurance_athlete you'll be eating (in 100s of grams or milliliters): \n",
      "\n",
      "                         Food  Quantity\n",
      "vermicelli made from soybeans      3.25\n",
      "            peanuts unroasted      1.15\n",
      "                   flax seeds      0.02\n",
      "           cereal toasted oat      3.52\n",
      " beans and rice with tomatoes      2.53\n",
      "            ripe plantain raw      1.53\n",
      "                 cilantro raw      0.23\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "\u001b[1m### Running diet optimization for Male_19_30 ###\u001b[0m\n",
      "\n",
      "Cost of diet for a vegan Male_19_30 is $3.84 per day.\n",
      "\n",
      "As a vegan Male_19_30 you'll be eating (in 100s of grams or milliliters): \n",
      "\n",
      "                         Food  Quantity\n",
      "    peruvian beans from dried      2.16\n",
      "vermicelli made from soybeans      3.67\n",
      "            peanuts unroasted      0.33\n",
      "           cereal rice flakes      0.31\n",
      "           cereal toasted oat      1.78\n",
      " beans and rice with tomatoes      6.40\n",
      "            ripe plantain raw      0.86\n",
      "                 cilantro raw      0.22\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "\u001b[1m### Running diet optimization for Male_endurance_athlete ###\u001b[0m\n",
      "\n",
      "Cost of diet for a vegan Male_endurance_athlete is $4.04 per day.\n",
      "\n",
      "As a vegan Male_endurance_athlete you'll be eating (in 100s of grams or milliliters): \n",
      "\n",
      "                         Food  Quantity\n",
      "    peruvian beans from dried      1.79\n",
      "vermicelli made from soybeans      3.21\n",
      "            peanuts unroasted      0.90\n",
      "           cereal rice flakes      0.74\n",
      "           cereal toasted oat      1.32\n",
      " beans and rice with tomatoes      7.50\n",
      "                 cilantro raw      0.22\n",
      "                     corn oil      0.23\n",
      "                    sugar nfs      0.58\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the demographic groups\n",
    "demographic_groups = ['Female_19_30', 'Female_endurance_athlete', 'Male_19_30', 'Male_endurance_athlete']\n",
    "\n",
    "# Dictionary to store results\n",
    "diet_results = {}\n",
    "\n",
    "# Loop through each group and run the function\n",
    "for group in demographic_groups:\n",
    "    print(f\"\\n\\033[1m### Running diet optimization for {group} ###\\033[0m\\n\")  # Bold title\n",
    "\n",
    "    diet_results[group] = calculate_vegan_diet_cost(group)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separation line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0f16b-c8ee-47b3-aab5-4b5295648be0",
   "metadata": {},
   "source": [
    " # Start CPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fd44e71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_id</th>\n",
       "      <th>ind_definition</th>\n",
       "      <th>reportyear</th>\n",
       "      <th>race_eth_code</th>\n",
       "      <th>race_eth_name</th>\n",
       "      <th>geotype</th>\n",
       "      <th>geotypevalue</th>\n",
       "      <th>geoname</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>...</th>\n",
       "      <th>median_income</th>\n",
       "      <th>affordability_ratio</th>\n",
       "      <th>LL95_affordability_ratio</th>\n",
       "      <th>UL95_affordability_ratio</th>\n",
       "      <th>se_food_afford</th>\n",
       "      <th>rse_food_afford</th>\n",
       "      <th>food_afford_decile</th>\n",
       "      <th>CA_RR_Affordability</th>\n",
       "      <th>ave_fam_size</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AIAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23777.0</td>\n",
       "      <td>0.315779</td>\n",
       "      <td>0.231517</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>0.042991</td>\n",
       "      <td>13.614342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.185347</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38508.0</td>\n",
       "      <td>0.194980</td>\n",
       "      <td>0.183065</td>\n",
       "      <td>0.206895</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>3.117814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AfricanAm</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26192.0</td>\n",
       "      <td>0.286664</td>\n",
       "      <td>0.279661</td>\n",
       "      <td>0.293666</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>1.246349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.076054</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Latino</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22858.0</td>\n",
       "      <td>0.328475</td>\n",
       "      <td>0.322637</td>\n",
       "      <td>0.334314</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.906881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.233004</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NHOPI</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36737.0</td>\n",
       "      <td>0.204379</td>\n",
       "      <td>0.173762</td>\n",
       "      <td>0.234997</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>7.643255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767183</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ind_id                                     ind_definition reportyear  \\\n",
       "0    757  Food affordability for female-headed household...  2006-2010   \n",
       "1    757  Food affordability for female-headed household...  2006-2010   \n",
       "2    757  Food affordability for female-headed household...  2006-2010   \n",
       "3    757  Food affordability for female-headed household...  2006-2010   \n",
       "4    757  Food affordability for female-headed household...  2006-2010   \n",
       "\n",
       "   race_eth_code race_eth_name geotype  geotypevalue     geoname county_name  \\\n",
       "0            1.0          AIAN      CA           6.0  California         NaN   \n",
       "1            2.0         Asian      CA           6.0  California         NaN   \n",
       "2            3.0     AfricanAm      CA           6.0  California         NaN   \n",
       "3            4.0        Latino      CA           6.0  California         NaN   \n",
       "4            5.0         NHOPI      CA           6.0  California         NaN   \n",
       "\n",
       "   county_fips  ... median_income  affordability_ratio  \\\n",
       "0          NaN  ...       23777.0             0.315779   \n",
       "1          NaN  ...       38508.0             0.194980   \n",
       "2          NaN  ...       26192.0             0.286664   \n",
       "3          NaN  ...       22858.0             0.328475   \n",
       "4          NaN  ...       36737.0             0.204379   \n",
       "\n",
       "   LL95_affordability_ratio  UL95_affordability_ratio  se_food_afford  \\\n",
       "0                  0.231517                  0.400043        0.042991   \n",
       "1                  0.183065                  0.206895        0.006079   \n",
       "2                  0.279661                  0.293666        0.003573   \n",
       "3                  0.322637                  0.334314        0.002979   \n",
       "4                  0.173762                  0.234997        0.015621   \n",
       "\n",
       "   rse_food_afford  food_afford_decile  CA_RR_Affordability  ave_fam_size  \\\n",
       "0        13.614342                 NaN             1.185347          3.34   \n",
       "1         3.117814                 NaN             0.731900          3.34   \n",
       "2         1.246349                 NaN             1.076054          3.34   \n",
       "3         0.906881                 NaN             1.233004          3.34   \n",
       "4         7.643255                 NaN             0.767183          3.34   \n",
       "\n",
       "                  version  \n",
       "0 2013-04-12 04:33:06.235  \n",
       "1 2013-04-12 04:33:06.235  \n",
       "2 2013-04-12 04:33:06.235  \n",
       "3 2013-04-12 04:33:06.235  \n",
       "4 2013-04-12 04:33:06.235  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/home/jovyan/Project2/CPI/food_affordability_CA.xls'\n",
    "affordability_CA = pd.read_excel(file_path)\n",
    "affordability_CA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47f7fe",
   "metadata": {},
   "source": [
    "## Regional Differences in Minimum Cost Diet For Each Group ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "003f87fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /srv/conda/lib/python3.11/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Package Installations\n",
    "import pandas as pd\n",
    "import os\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c724f500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_id</th>\n",
       "      <th>ind_definition</th>\n",
       "      <th>reportyear</th>\n",
       "      <th>race_eth_code</th>\n",
       "      <th>race_eth_name</th>\n",
       "      <th>geotype</th>\n",
       "      <th>geotypevalue</th>\n",
       "      <th>geoname</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>...</th>\n",
       "      <th>median_income</th>\n",
       "      <th>affordability_ratio</th>\n",
       "      <th>LL95_affordability_ratio</th>\n",
       "      <th>UL95_affordability_ratio</th>\n",
       "      <th>se_food_afford</th>\n",
       "      <th>rse_food_afford</th>\n",
       "      <th>food_afford_decile</th>\n",
       "      <th>CA_RR_Affordability</th>\n",
       "      <th>ave_fam_size</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AIAN</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23777.0</td>\n",
       "      <td>0.315779</td>\n",
       "      <td>0.231517</td>\n",
       "      <td>0.400043</td>\n",
       "      <td>0.042991</td>\n",
       "      <td>13.614342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.185347</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38508.0</td>\n",
       "      <td>0.194980</td>\n",
       "      <td>0.183065</td>\n",
       "      <td>0.206895</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>3.117814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AfricanAm</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26192.0</td>\n",
       "      <td>0.286664</td>\n",
       "      <td>0.279661</td>\n",
       "      <td>0.293666</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>1.246349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.076054</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Latino</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22858.0</td>\n",
       "      <td>0.328475</td>\n",
       "      <td>0.322637</td>\n",
       "      <td>0.334314</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.906881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.233004</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>757</td>\n",
       "      <td>Food affordability for female-headed household...</td>\n",
       "      <td>2006-2010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NHOPI</td>\n",
       "      <td>CA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36737.0</td>\n",
       "      <td>0.204379</td>\n",
       "      <td>0.173762</td>\n",
       "      <td>0.234997</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>7.643255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767183</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2013-04-12 04:33:06.235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ind_id                                     ind_definition reportyear  \\\n",
       "0    757  Food affordability for female-headed household...  2006-2010   \n",
       "1    757  Food affordability for female-headed household...  2006-2010   \n",
       "2    757  Food affordability for female-headed household...  2006-2010   \n",
       "3    757  Food affordability for female-headed household...  2006-2010   \n",
       "4    757  Food affordability for female-headed household...  2006-2010   \n",
       "\n",
       "   race_eth_code race_eth_name geotype  geotypevalue     geoname county_name  \\\n",
       "0            1.0          AIAN      CA           6.0  California         NaN   \n",
       "1            2.0         Asian      CA           6.0  California         NaN   \n",
       "2            3.0     AfricanAm      CA           6.0  California         NaN   \n",
       "3            4.0        Latino      CA           6.0  California         NaN   \n",
       "4            5.0         NHOPI      CA           6.0  California         NaN   \n",
       "\n",
       "   county_fips  ... median_income  affordability_ratio  \\\n",
       "0          NaN  ...       23777.0             0.315779   \n",
       "1          NaN  ...       38508.0             0.194980   \n",
       "2          NaN  ...       26192.0             0.286664   \n",
       "3          NaN  ...       22858.0             0.328475   \n",
       "4          NaN  ...       36737.0             0.204379   \n",
       "\n",
       "   LL95_affordability_ratio  UL95_affordability_ratio  se_food_afford  \\\n",
       "0                  0.231517                  0.400043        0.042991   \n",
       "1                  0.183065                  0.206895        0.006079   \n",
       "2                  0.279661                  0.293666        0.003573   \n",
       "3                  0.322637                  0.334314        0.002979   \n",
       "4                  0.173762                  0.234997        0.015621   \n",
       "\n",
       "   rse_food_afford  food_afford_decile  CA_RR_Affordability  ave_fam_size  \\\n",
       "0        13.614342                 NaN             1.185347          3.34   \n",
       "1         3.117814                 NaN             0.731900          3.34   \n",
       "2         1.246349                 NaN             1.076054          3.34   \n",
       "3         0.906881                 NaN             1.233004          3.34   \n",
       "4         7.643255                 NaN             0.767183          3.34   \n",
       "\n",
       "                  version  \n",
       "0 2013-04-12 04:33:06.235  \n",
       "1 2013-04-12 04:33:06.235  \n",
       "2 2013-04-12 04:33:06.235  \n",
       "3 2013-04-12 04:33:06.235  \n",
       "4 2013-04-12 04:33:06.235  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/home/jovyan/Project2/CPI/food_affordability_CA.xls'\n",
    "affordability_CA = pd.read_excel(file_path)\n",
    "affordability_CA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7aaf9",
   "metadata": {},
   "source": [
    "## Regional CPI ##\n",
    "\n",
    "The followings are the census divisions: \n",
    "New England, Middle Atlantic, East North Central, West North Central, South Atlantic, East South Central, West South Central, Mountain, and  Pacific. Each dataframe has the CPI for each census region with the monthly CPI changes as well as annual and first half and second half. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "71236ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Annual</th>\n",
       "      <th>HALF1</th>\n",
       "      <th>HALF2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>100.553</td>\n",
       "      <td>100.987</td>\n",
       "      <td>101.314</td>\n",
       "      <td>101.786</td>\n",
       "      <td>102.112</td>\n",
       "      <td>102.204</td>\n",
       "      <td>102.203</td>\n",
       "      <td>101.993</td>\n",
       "      <td>101.879</td>\n",
       "      <td>102.217</td>\n",
       "      <td>101.814</td>\n",
       "      <td>100.929</td>\n",
       "      <td>101.666</td>\n",
       "      <td>101.493</td>\n",
       "      <td>101.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>101.116</td>\n",
       "      <td>101.712</td>\n",
       "      <td>102.336</td>\n",
       "      <td>102.541</td>\n",
       "      <td>102.455</td>\n",
       "      <td>102.478</td>\n",
       "      <td>102.724</td>\n",
       "      <td>102.590</td>\n",
       "      <td>102.397</td>\n",
       "      <td>102.457</td>\n",
       "      <td>102.530</td>\n",
       "      <td>102.426</td>\n",
       "      <td>102.314</td>\n",
       "      <td>102.106</td>\n",
       "      <td>102.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>102.776</td>\n",
       "      <td>102.771</td>\n",
       "      <td>102.751</td>\n",
       "      <td>101.878</td>\n",
       "      <td>101.703</td>\n",
       "      <td>102.401</td>\n",
       "      <td>103.319</td>\n",
       "      <td>103.617</td>\n",
       "      <td>103.581</td>\n",
       "      <td>103.820</td>\n",
       "      <td>103.710</td>\n",
       "      <td>104.179</td>\n",
       "      <td>103.042</td>\n",
       "      <td>102.380</td>\n",
       "      <td>103.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>105.077</td>\n",
       "      <td>105.706</td>\n",
       "      <td>106.817</td>\n",
       "      <td>107.669</td>\n",
       "      <td>108.861</td>\n",
       "      <td>109.882</td>\n",
       "      <td>110.293</td>\n",
       "      <td>110.235</td>\n",
       "      <td>110.370</td>\n",
       "      <td>111.341</td>\n",
       "      <td>111.793</td>\n",
       "      <td>111.575</td>\n",
       "      <td>109.135</td>\n",
       "      <td>107.335</td>\n",
       "      <td>110.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022</td>\n",
       "      <td>112.368</td>\n",
       "      <td>113.558</td>\n",
       "      <td>115.235</td>\n",
       "      <td>116.043</td>\n",
       "      <td>117.285</td>\n",
       "      <td>119.152</td>\n",
       "      <td>119.130</td>\n",
       "      <td>118.532</td>\n",
       "      <td>118.540</td>\n",
       "      <td>118.947</td>\n",
       "      <td>118.830</td>\n",
       "      <td>118.814</td>\n",
       "      <td>117.203</td>\n",
       "      <td>115.607</td>\n",
       "      <td>118.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023</td>\n",
       "      <td>119.810</td>\n",
       "      <td>120.973</td>\n",
       "      <td>121.282</td>\n",
       "      <td>122.069</td>\n",
       "      <td>122.567</td>\n",
       "      <td>123.082</td>\n",
       "      <td>123.385</td>\n",
       "      <td>123.838</td>\n",
       "      <td>123.999</td>\n",
       "      <td>123.920</td>\n",
       "      <td>123.556</td>\n",
       "      <td>123.186</td>\n",
       "      <td>122.639</td>\n",
       "      <td>121.631</td>\n",
       "      <td>123.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024</td>\n",
       "      <td>124.107</td>\n",
       "      <td>125.231</td>\n",
       "      <td>126.131</td>\n",
       "      <td>126.846</td>\n",
       "      <td>127.152</td>\n",
       "      <td>127.224</td>\n",
       "      <td>127.317</td>\n",
       "      <td>127.445</td>\n",
       "      <td>127.966</td>\n",
       "      <td>128.254</td>\n",
       "      <td>128.459</td>\n",
       "      <td>128.250</td>\n",
       "      <td>127.032</td>\n",
       "      <td>126.115</td>\n",
       "      <td>127.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025</td>\n",
       "      <td>128.938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Jan      Feb      Mar      Apr      May      Jun      Jul  \\\n",
       "0  2017      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1  2018  100.553  100.987  101.314  101.786  102.112  102.204  102.203   \n",
       "2  2019  101.116  101.712  102.336  102.541  102.455  102.478  102.724   \n",
       "3  2020  102.776  102.771  102.751  101.878  101.703  102.401  103.319   \n",
       "4  2021  105.077  105.706  106.817  107.669  108.861  109.882  110.293   \n",
       "5  2022  112.368  113.558  115.235  116.043  117.285  119.152  119.130   \n",
       "6  2023  119.810  120.973  121.282  122.069  122.567  123.082  123.385   \n",
       "7  2024  124.107  125.231  126.131  126.846  127.152  127.224  127.317   \n",
       "8  2025  128.938      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "       Aug      Sep      Oct      Nov      Dec   Annual    HALF1    HALF2  \n",
       "0      NaN      NaN      NaN      NaN  100.000      NaN      NaN      NaN  \n",
       "1  101.993  101.879  102.217  101.814  100.929  101.666  101.493  101.839  \n",
       "2  102.590  102.397  102.457  102.530  102.426  102.314  102.106  102.521  \n",
       "3  103.617  103.581  103.820  103.710  104.179  103.042  102.380  103.704  \n",
       "4  110.235  110.370  111.341  111.793  111.575  109.135  107.335  110.935  \n",
       "5  118.532  118.540  118.947  118.830  118.814  117.203  115.607  118.799  \n",
       "6  123.838  123.999  123.920  123.556  123.186  122.639  121.631  123.647  \n",
       "7  127.445  127.966  128.254  128.459  128.250  127.032  126.115  127.949  \n",
       "8      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All the file path\n",
    "file_path_1 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_EastSouthCentral.csv'\n",
    "file_path_2 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_MiddleAtlantic.csv'\n",
    "file_path_3 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_East_North_Central.csv'\n",
    "file_path_4 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_Mountain.csv'\n",
    "file_path_5 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_NewEngland.csv'\n",
    "file_path_6 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_Pacific.csv'\n",
    "file_path_7 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_SouthAtlantic.csv'\n",
    "file_path_8 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_WestNorthCentral.csv'\n",
    "file_path_9 = '/home/jovyan/Project2/CPI/Census_Divisions/CPI_WestSouthCentral.csv'\n",
    "\n",
    "#individual files for each census regions\n",
    "CPI_East_South_Central = pd.read_csv(file_path_1)\n",
    "CPI_Middle_Atlantic = pd.read_csv(file_path_2)\n",
    "CPI_East_North_Central = pd.read_csv(file_path_3)\n",
    "CPI_Mountain = pd.read_csv(file_path_4)\n",
    "CPI_NewEngland = pd.read_csv(file_path_5)\n",
    "CPI_Pacific = pd.read_csv(file_path_6)\n",
    "CPI_South_Atlantic = pd.read_csv(file_path_7)\n",
    "CPI_West_North_Central = pd.read_csv(file_path_8)\n",
    "CPI_West_South_Central = pd.read_csv(file_path_9)\n",
    "\n",
    "#example of a dataframe\n",
    "CPI_East_South_Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07bea9",
   "metadata": {},
   "source": [
    "## Clean the Dataframe to make it easier to work with ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c12eeb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Annual</th>\n",
       "      <th>HALF1</th>\n",
       "      <th>HALF2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>100.694</td>\n",
       "      <td>100.780</td>\n",
       "      <td>100.903</td>\n",
       "      <td>101.429</td>\n",
       "      <td>101.892</td>\n",
       "      <td>101.984</td>\n",
       "      <td>101.849</td>\n",
       "      <td>101.800</td>\n",
       "      <td>101.977</td>\n",
       "      <td>101.982</td>\n",
       "      <td>101.569</td>\n",
       "      <td>101.226</td>\n",
       "      <td>101.507</td>\n",
       "      <td>101.280</td>\n",
       "      <td>101.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>101.457</td>\n",
       "      <td>102.212</td>\n",
       "      <td>102.656</td>\n",
       "      <td>102.928</td>\n",
       "      <td>103.246</td>\n",
       "      <td>103.178</td>\n",
       "      <td>103.432</td>\n",
       "      <td>103.521</td>\n",
       "      <td>103.564</td>\n",
       "      <td>103.804</td>\n",
       "      <td>103.614</td>\n",
       "      <td>103.605</td>\n",
       "      <td>103.101</td>\n",
       "      <td>102.613</td>\n",
       "      <td>103.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>104.130</td>\n",
       "      <td>104.271</td>\n",
       "      <td>103.675</td>\n",
       "      <td>102.423</td>\n",
       "      <td>102.887</td>\n",
       "      <td>103.724</td>\n",
       "      <td>104.254</td>\n",
       "      <td>104.745</td>\n",
       "      <td>104.842</td>\n",
       "      <td>104.787</td>\n",
       "      <td>104.456</td>\n",
       "      <td>104.479</td>\n",
       "      <td>104.056</td>\n",
       "      <td>103.518</td>\n",
       "      <td>104.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>105.024</td>\n",
       "      <td>105.925</td>\n",
       "      <td>106.623</td>\n",
       "      <td>107.470</td>\n",
       "      <td>108.498</td>\n",
       "      <td>109.476</td>\n",
       "      <td>110.136</td>\n",
       "      <td>110.248</td>\n",
       "      <td>110.465</td>\n",
       "      <td>111.421</td>\n",
       "      <td>111.949</td>\n",
       "      <td>112.265</td>\n",
       "      <td>109.125</td>\n",
       "      <td>107.169</td>\n",
       "      <td>111.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>113.270</td>\n",
       "      <td>114.287</td>\n",
       "      <td>115.714</td>\n",
       "      <td>116.197</td>\n",
       "      <td>118.062</td>\n",
       "      <td>120.218</td>\n",
       "      <td>119.823</td>\n",
       "      <td>119.483</td>\n",
       "      <td>119.794</td>\n",
       "      <td>120.134</td>\n",
       "      <td>119.877</td>\n",
       "      <td>119.173</td>\n",
       "      <td>118.003</td>\n",
       "      <td>116.291</td>\n",
       "      <td>119.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>120.275</td>\n",
       "      <td>120.738</td>\n",
       "      <td>121.651</td>\n",
       "      <td>122.432</td>\n",
       "      <td>122.832</td>\n",
       "      <td>123.181</td>\n",
       "      <td>123.558</td>\n",
       "      <td>123.424</td>\n",
       "      <td>123.278</td>\n",
       "      <td>123.157</td>\n",
       "      <td>123.038</td>\n",
       "      <td>122.867</td>\n",
       "      <td>122.536</td>\n",
       "      <td>121.852</td>\n",
       "      <td>123.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>123.327</td>\n",
       "      <td>123.920</td>\n",
       "      <td>124.812</td>\n",
       "      <td>125.474</td>\n",
       "      <td>125.803</td>\n",
       "      <td>125.927</td>\n",
       "      <td>126.529</td>\n",
       "      <td>126.534</td>\n",
       "      <td>126.541</td>\n",
       "      <td>126.517</td>\n",
       "      <td>126.402</td>\n",
       "      <td>126.635</td>\n",
       "      <td>125.702</td>\n",
       "      <td>124.877</td>\n",
       "      <td>126.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>127.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug  \\\n",
       "Year                                                                           \n",
       "2017      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018  100.694  100.780  100.903  101.429  101.892  101.984  101.849  101.800   \n",
       "2019  101.457  102.212  102.656  102.928  103.246  103.178  103.432  103.521   \n",
       "2020  104.130  104.271  103.675  102.423  102.887  103.724  104.254  104.745   \n",
       "2021  105.024  105.925  106.623  107.470  108.498  109.476  110.136  110.248   \n",
       "2022  113.270  114.287  115.714  116.197  118.062  120.218  119.823  119.483   \n",
       "2023  120.275  120.738  121.651  122.432  122.832  123.181  123.558  123.424   \n",
       "2024  123.327  123.920  124.812  125.474  125.803  125.927  126.529  126.534   \n",
       "2025  127.521      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "          Sep      Oct      Nov      Dec   Annual    HALF1    HALF2  \n",
       "Year                                                                 \n",
       "2017      NaN      NaN      NaN  100.000      NaN      NaN      NaN  \n",
       "2018  101.977  101.982  101.569  101.226  101.507  101.280  101.734  \n",
       "2019  103.564  103.804  103.614  103.605  103.101  102.613  103.590  \n",
       "2020  104.842  104.787  104.456  104.479  104.056  103.518  104.594  \n",
       "2021  110.465  111.421  111.949  112.265  109.125  107.169  111.081  \n",
       "2022  119.794  120.134  119.877  119.173  118.003  116.291  119.714  \n",
       "2023  123.278  123.157  123.038  122.867  122.536  121.852  123.220  \n",
       "2024  126.541  126.517  126.402  126.635  125.702  124.877  126.526  \n",
       "2025      NaN      NaN      NaN      NaN      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary of DataFrames\n",
    "cpi_dfs = {\n",
    "    \"CPI_East_South_Central\": CPI_East_South_Central,\n",
    "    \"CPI_Middle_Atlantic\": CPI_Middle_Atlantic,\n",
    "    \"CPI_East_North_Central\": CPI_East_North_Central,\n",
    "    \"CPI_Mountain\": CPI_Mountain,\n",
    "    \"CPI_NewEngland\": CPI_NewEngland,\n",
    "    \"CPI_Pacific\": CPI_Pacific,\n",
    "    \"CPI_South_Atlantic\": CPI_South_Atlantic,\n",
    "    \"CPI_West_North_Central\": CPI_West_North_Central,\n",
    "    \"CPI_West_South_Central\": CPI_West_South_Central\n",
    "}\n",
    "\n",
    "# Loop through all DataFrames and set \"Year\" as the index\n",
    "for name, df in cpi_dfs.items():\n",
    "    if \"Year\" in df.columns:  # Check if \"Year\" column exists\n",
    "        df.set_index(\"Year\", inplace=True)\n",
    "\n",
    "# Now all DataFrames have \"Year\" as the index\n",
    "\n",
    "CPI_East_North_Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cddac5d",
   "metadata": {},
   "source": [
    "2017 is the base year for CPI calculation for all the dataframe. We will use the formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8712fab",
   "metadata": {},
   "source": [
    "## Calculating Adjusted Cost of Minimum Diet Using CPI\n",
    "\n",
    "To determine the cost of a minimum diet for each region, we use the Consumer Price Index (CPI) as an adjustment factor. The formula is given by:\n",
    "\n",
    "$$\n",
    "\\text{Adjusted Cost}_{\\text{region}} = \\text{Base Cost} \\times \\frac{\\text{CPI}_{\\text{region}}}{\\text{CPI}_{\\text{base}}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **$\\text{Adjusted Cost}_{\\text{region}}$** is the estimated cost of the minimum diet in the specific region.\n",
    "- **$\\text{Base Cost}$** is the reference cost of the minimum diet (typically from a standard region or dataset).\n",
    "- **$\\text{CPI}_{\\text{region}}$** is the Consumer Price Index for the specific region.\n",
    "- **$\\text{CPI}_{\\text{base}}$** is the CPI of the reference region.\n",
    "\n",
    "This method adjusts the base cost according to regional price variations, ensuring that the diet cost reflects local economic conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7a6dc5",
   "metadata": {},
   "source": [
    "## Change the variable name and structure AFTER sorting out the FINAL files ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faad503",
   "metadata": {},
   "source": [
    "### Save the Minimum Cost Diet of Each Group as Variables ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4a773af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_price_vegan_m_endurance_ath = 4.04\n",
    "min_price_vegan_f_endurance_ath = 3.97\n",
    "min_price_vegan_m_endurance_ath = 3.77\n",
    "min_price_vegan_f_non_ath = 3.28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720af6a7",
   "metadata": {},
   "source": [
    "## The Calculated Adjusted Minimum Cost Diet as a Dataframe ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "41aa03ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Annual</th>\n",
       "      <th>HALF1</th>\n",
       "      <th>HALF2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>100.694</td>\n",
       "      <td>100.780</td>\n",
       "      <td>100.903</td>\n",
       "      <td>101.429</td>\n",
       "      <td>101.892</td>\n",
       "      <td>101.984</td>\n",
       "      <td>101.849</td>\n",
       "      <td>101.800</td>\n",
       "      <td>101.977</td>\n",
       "      <td>101.982</td>\n",
       "      <td>101.569</td>\n",
       "      <td>101.226</td>\n",
       "      <td>101.507</td>\n",
       "      <td>101.280</td>\n",
       "      <td>101.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>101.457</td>\n",
       "      <td>102.212</td>\n",
       "      <td>102.656</td>\n",
       "      <td>102.928</td>\n",
       "      <td>103.246</td>\n",
       "      <td>103.178</td>\n",
       "      <td>103.432</td>\n",
       "      <td>103.521</td>\n",
       "      <td>103.564</td>\n",
       "      <td>103.804</td>\n",
       "      <td>103.614</td>\n",
       "      <td>103.605</td>\n",
       "      <td>103.101</td>\n",
       "      <td>102.613</td>\n",
       "      <td>103.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>104.130</td>\n",
       "      <td>104.271</td>\n",
       "      <td>103.675</td>\n",
       "      <td>102.423</td>\n",
       "      <td>102.887</td>\n",
       "      <td>103.724</td>\n",
       "      <td>104.254</td>\n",
       "      <td>104.745</td>\n",
       "      <td>104.842</td>\n",
       "      <td>104.787</td>\n",
       "      <td>104.456</td>\n",
       "      <td>104.479</td>\n",
       "      <td>104.056</td>\n",
       "      <td>103.518</td>\n",
       "      <td>104.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>105.024</td>\n",
       "      <td>105.925</td>\n",
       "      <td>106.623</td>\n",
       "      <td>107.470</td>\n",
       "      <td>108.498</td>\n",
       "      <td>109.476</td>\n",
       "      <td>110.136</td>\n",
       "      <td>110.248</td>\n",
       "      <td>110.465</td>\n",
       "      <td>111.421</td>\n",
       "      <td>111.949</td>\n",
       "      <td>112.265</td>\n",
       "      <td>109.125</td>\n",
       "      <td>107.169</td>\n",
       "      <td>111.081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug  \\\n",
       "Year                                                                           \n",
       "2017      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2018  100.694  100.780  100.903  101.429  101.892  101.984  101.849  101.800   \n",
       "2019  101.457  102.212  102.656  102.928  103.246  103.178  103.432  103.521   \n",
       "2020  104.130  104.271  103.675  102.423  102.887  103.724  104.254  104.745   \n",
       "2021  105.024  105.925  106.623  107.470  108.498  109.476  110.136  110.248   \n",
       "\n",
       "          Sep      Oct      Nov      Dec   Annual    HALF1    HALF2  \n",
       "Year                                                                 \n",
       "2017      NaN      NaN      NaN  100.000      NaN      NaN      NaN  \n",
       "2018  101.977  101.982  101.569  101.226  101.507  101.280  101.734  \n",
       "2019  103.564  103.804  103.614  103.605  103.101  102.613  103.590  \n",
       "2020  104.842  104.787  104.456  104.479  104.056  103.518  104.594  \n",
       "2021  110.465  111.421  111.949  112.265  109.125  107.169  111.081  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPI_East_North_Central.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d0fca9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Adjusted_Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>4.789106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>4.703904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>4.738965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>4.949859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.654744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>4.851802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>4.886486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>4.770370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>4.726034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Region  Adjusted_Cost\n",
       "0  East_South_Central       4.789106\n",
       "1     Middle_Atlantic       4.703904\n",
       "2  East_North_Central       4.738965\n",
       "3            Mountain       4.949859\n",
       "4          NewEngland       4.654744\n",
       "5             Pacific       4.851802\n",
       "6      South_Atlantic       4.886486\n",
       "7  West_North_Central       4.770370\n",
       "8  West_South_Central       4.726034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary containing all CPI DataFrames\n",
    "cpi_dfs = {\n",
    "    \"East_South_Central\": CPI_East_South_Central,\n",
    "    \"Middle_Atlantic\": CPI_Middle_Atlantic,\n",
    "    \"East_North_Central\": CPI_East_North_Central,\n",
    "    \"Mountain\": CPI_Mountain,\n",
    "    \"NewEngland\": CPI_NewEngland,\n",
    "    \"Pacific\": CPI_Pacific,\n",
    "    \"South_Atlantic\": CPI_South_Atlantic,\n",
    "    \"West_North_Central\": CPI_West_North_Central,\n",
    "    \"West_South_Central\": CPI_West_South_Central\n",
    "}\n",
    "\n",
    "# Define base year and minimum cost of diet\n",
    "base_year = 2017  #  CPI base year for all census region\n",
    "min_price_vegan_m_endurance_ath = min_price_vegan_m_endurance_ath \n",
    "\n",
    "# Create an empty list to store results\n",
    "adjusted_cost_data = []\n",
    "\n",
    "# Loop through each region's CPI data\n",
    "for region, df in cpi_dfs.items():\n",
    "    # Ensure Year is the index and fetch CPI values\n",
    "    if base_year in df.index and 2024 in df.index:\n",
    "        cpi_base = df.loc[base_year, \"Dec\"]  # CPI for base year is given in December\n",
    "        cpi_latest = df.loc[2024, \"Annual\"]  # CPI for latest available year which is 2024\n",
    "        # Calculate adjusted diet cost\n",
    "        adjusted_cost = min_price_vegan_m_endurance_ath * (cpi_latest / cpi_base)\n",
    "        \n",
    "        # Append results\n",
    "        adjusted_cost_data.append([region, adjusted_cost])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "adjusted_cost_df = pd.DataFrame(adjusted_cost_data, columns=[\"Region\", \"Adjusted_Cost\"])\n",
    "\n",
    "# Display the DataFrame in Jupyter Notebook\n",
    "display(adjusted_cost_df)  # For Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ddfe5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_cost_by_cpi(min_price, cpi_dfs, base_year=2017, latest_year=2024):\n",
    "    \"\"\"\n",
    "    Adjusts a base diet cost using CPI data from multiple regions and returns\n",
    "    a DataFrame with the region name and adjusted costs.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    min_price : float\n",
    "        Minimum diet cost to be adjusted (e.g., min_price_vegan_m_endurance_ath)\n",
    "    cpi_dfs : dict of pd.DataFrame\n",
    "        Dictionary keyed by region. Each value is a DataFrame with CPI data for multiple years,\n",
    "        where the DataFrame index is years, and includes columns like 'Dec' and 'Annual'\n",
    "    base_year : int, default 2017\n",
    "        The year in the DataFrame(s) to use as a CPI base.\n",
    "    latest_year : int, default 2024\n",
    "        The year in the DataFrame(s) to use as the CPI for the latest adjustment.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with columns [\"Region\", \"Adjusted_Cost\"] where \"Region\" is the key\n",
    "        from the dictionary, and \"Adjusted_Cost\" is the adjusted cost for that region.\n",
    "    \"\"\"\n",
    "    adjusted_cost_data = []\n",
    "\n",
    "    for region, df in cpi_dfs.items():\n",
    "        # We check both the base and latest years are present in the index\n",
    "        if base_year in df.index and latest_year in df.index:\n",
    "            cpi_base = df.loc[base_year, \"Dec\"]\n",
    "            cpi_latest = df.loc[latest_year, \"Annual\"]\n",
    "            \n",
    "            # Calculate the adjusted cost\n",
    "            adjusted_cost = min_price * (cpi_latest / cpi_base)\n",
    "            \n",
    "            # Append to our list of results\n",
    "            adjusted_cost_data.append([region, adjusted_cost])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    adjusted_cost_df = pd.DataFrame(adjusted_cost_data, columns=[\"Region\", \"Adjusted_Cost\"])\n",
    "\n",
    "    return adjusted_cost_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fcf48dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_price_vegan_m_endurance_ath = 4.04\n",
    "min_price_vegan_f_endurance_ath = 3.97\n",
    "min_price_vegan_m_non_ath = 3.77\n",
    "min_price_vegan_f_non_ath = 3.28\n",
    "\n",
    "diet_costs = {\n",
    "    \"vegan_m_endurance_ath\": min_price_vegan_m_endurance_ath,\n",
    "    \"vegan_f_endurance_ath\": min_price_vegan_f_endurance_ath,\n",
    "    \"vegan_m_non_ath\": min_price_vegan_m_non_ath,\n",
    "    \"vegan_f_non_ath\": min_price_vegan_f_non_ath,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7a5246d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Adjusted_Cost</th>\n",
       "      <th>Diet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>5.132093</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>5.040789</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>5.078361</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>5.304358</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.988107</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>5.199278</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>5.236446</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>5.112014</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>5.064504</td>\n",
       "      <td>vegan_m_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>5.043170</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>4.953448</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>4.990369</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>5.212451</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.901680</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>5.109192</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>5.145716</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>5.023440</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>4.976752</td>\n",
       "      <td>vegan_f_endurance_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>4.789106</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>4.703904</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>4.738965</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>4.949859</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.654744</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>4.851802</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>4.886486</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>4.770370</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>4.726034</td>\n",
       "      <td>vegan_m_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>East_South_Central</td>\n",
       "      <td>4.166650</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Middle_Atlantic</td>\n",
       "      <td>4.092522</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>East_North_Central</td>\n",
       "      <td>4.123026</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>4.306509</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NewEngland</td>\n",
       "      <td>4.049750</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>4.221196</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>South_Atlantic</td>\n",
       "      <td>4.251372</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>West_North_Central</td>\n",
       "      <td>4.150348</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>West_South_Central</td>\n",
       "      <td>4.111775</td>\n",
       "      <td>vegan_f_non_ath</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Region  Adjusted_Cost              Diet_Type\n",
       "0   East_South_Central       5.132093  vegan_m_endurance_ath\n",
       "1      Middle_Atlantic       5.040789  vegan_m_endurance_ath\n",
       "2   East_North_Central       5.078361  vegan_m_endurance_ath\n",
       "3             Mountain       5.304358  vegan_m_endurance_ath\n",
       "4           NewEngland       4.988107  vegan_m_endurance_ath\n",
       "5              Pacific       5.199278  vegan_m_endurance_ath\n",
       "6       South_Atlantic       5.236446  vegan_m_endurance_ath\n",
       "7   West_North_Central       5.112014  vegan_m_endurance_ath\n",
       "8   West_South_Central       5.064504  vegan_m_endurance_ath\n",
       "9   East_South_Central       5.043170  vegan_f_endurance_ath\n",
       "10     Middle_Atlantic       4.953448  vegan_f_endurance_ath\n",
       "11  East_North_Central       4.990369  vegan_f_endurance_ath\n",
       "12            Mountain       5.212451  vegan_f_endurance_ath\n",
       "13          NewEngland       4.901680  vegan_f_endurance_ath\n",
       "14             Pacific       5.109192  vegan_f_endurance_ath\n",
       "15      South_Atlantic       5.145716  vegan_f_endurance_ath\n",
       "16  West_North_Central       5.023440  vegan_f_endurance_ath\n",
       "17  West_South_Central       4.976752  vegan_f_endurance_ath\n",
       "18  East_South_Central       4.789106        vegan_m_non_ath\n",
       "19     Middle_Atlantic       4.703904        vegan_m_non_ath\n",
       "20  East_North_Central       4.738965        vegan_m_non_ath\n",
       "21            Mountain       4.949859        vegan_m_non_ath\n",
       "22          NewEngland       4.654744        vegan_m_non_ath\n",
       "23             Pacific       4.851802        vegan_m_non_ath\n",
       "24      South_Atlantic       4.886486        vegan_m_non_ath\n",
       "25  West_North_Central       4.770370        vegan_m_non_ath\n",
       "26  West_South_Central       4.726034        vegan_m_non_ath\n",
       "27  East_South_Central       4.166650        vegan_f_non_ath\n",
       "28     Middle_Atlantic       4.092522        vegan_f_non_ath\n",
       "29  East_North_Central       4.123026        vegan_f_non_ath\n",
       "30            Mountain       4.306509        vegan_f_non_ath\n",
       "31          NewEngland       4.049750        vegan_f_non_ath\n",
       "32             Pacific       4.221196        vegan_f_non_ath\n",
       "33      South_Atlantic       4.251372        vegan_f_non_ath\n",
       "34  West_North_Central       4.150348        vegan_f_non_ath\n",
       "35  West_South_Central       4.111775        vegan_f_non_ath"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_adjusted_results = []\n",
    "\n",
    "for diet_name, min_price_val in diet_costs.items():\n",
    "    result_df = adjust_cost_by_cpi(min_price_val, cpi_dfs)\n",
    "    # Add a column to identify which diet cost this row corresponds to\n",
    "    result_df[\"Diet_Type\"] = diet_name\n",
    "    all_adjusted_results.append(result_df)\n",
    "\n",
    "# Concatenate all results into one DataFrame\n",
    "final_adjusted_costs_df = pd.concat(all_adjusted_results, ignore_index=True)\n",
    "\n",
    "final_adjusted_costs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f675e5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Diet_Type</th>\n",
       "      <th>vegan_f_endurance_ath</th>\n",
       "      <th>vegan_f_non_ath</th>\n",
       "      <th>vegan_m_endurance_ath</th>\n",
       "      <th>vegan_m_non_ath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>East_North_Central</th>\n",
       "      <td>4.990369</td>\n",
       "      <td>4.123026</td>\n",
       "      <td>5.078361</td>\n",
       "      <td>4.738965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East_South_Central</th>\n",
       "      <td>5.043170</td>\n",
       "      <td>4.166650</td>\n",
       "      <td>5.132093</td>\n",
       "      <td>4.789106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middle_Atlantic</th>\n",
       "      <td>4.953448</td>\n",
       "      <td>4.092522</td>\n",
       "      <td>5.040789</td>\n",
       "      <td>4.703904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mountain</th>\n",
       "      <td>5.212451</td>\n",
       "      <td>4.306509</td>\n",
       "      <td>5.304358</td>\n",
       "      <td>4.949859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewEngland</th>\n",
       "      <td>4.901680</td>\n",
       "      <td>4.049750</td>\n",
       "      <td>4.988107</td>\n",
       "      <td>4.654744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pacific</th>\n",
       "      <td>5.109192</td>\n",
       "      <td>4.221196</td>\n",
       "      <td>5.199278</td>\n",
       "      <td>4.851802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South_Atlantic</th>\n",
       "      <td>5.145716</td>\n",
       "      <td>4.251372</td>\n",
       "      <td>5.236446</td>\n",
       "      <td>4.886486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West_North_Central</th>\n",
       "      <td>5.023440</td>\n",
       "      <td>4.150348</td>\n",
       "      <td>5.112014</td>\n",
       "      <td>4.770370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West_South_Central</th>\n",
       "      <td>4.976752</td>\n",
       "      <td>4.111775</td>\n",
       "      <td>5.064504</td>\n",
       "      <td>4.726034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Diet_Type           vegan_f_endurance_ath  vegan_f_non_ath  \\\n",
       "Region                                                       \n",
       "East_North_Central               4.990369         4.123026   \n",
       "East_South_Central               5.043170         4.166650   \n",
       "Middle_Atlantic                  4.953448         4.092522   \n",
       "Mountain                         5.212451         4.306509   \n",
       "NewEngland                       4.901680         4.049750   \n",
       "Pacific                          5.109192         4.221196   \n",
       "South_Atlantic                   5.145716         4.251372   \n",
       "West_North_Central               5.023440         4.150348   \n",
       "West_South_Central               4.976752         4.111775   \n",
       "\n",
       "Diet_Type           vegan_m_endurance_ath  vegan_m_non_ath  \n",
       "Region                                                      \n",
       "East_North_Central               5.078361         4.738965  \n",
       "East_South_Central               5.132093         4.789106  \n",
       "Middle_Atlantic                  5.040789         4.703904  \n",
       "Mountain                         5.304358         4.949859  \n",
       "NewEngland                       4.988107         4.654744  \n",
       "Pacific                          5.199278         4.851802  \n",
       "South_Atlantic                   5.236446         4.886486  \n",
       "West_North_Central               5.112014         4.770370  \n",
       "West_South_Central               5.064504         4.726034  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the table\n",
    "pivoted_df = final_adjusted_costs_df.pivot(\n",
    "    index=\"Region\", \n",
    "    columns=\"Diet_Type\", \n",
    "    values=\"Adjusted_Cost\"\n",
    ")\n",
    "\n",
    "# Optionally, you might want to sort the index or columns:\n",
    "pivoted_df = pivoted_df.sort_index().sort_index(axis=1)\n",
    "\n",
    "# Show the pivoted table\n",
    "pivoted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d8f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
